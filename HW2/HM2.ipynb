{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HM2: Numerical Optimization for Logistic Regression.\n",
    "\n",
    "### Name: Vincent Lee\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read the lecture note: [click here](https://github.com/wangshusen/DeepLearning/blob/master/LectureNotes/Logistic/paper/logistic.pdf)\n",
    "\n",
    "2. Read, complete, and run my code.\n",
    "\n",
    "3. **Implement mini-batch SGD** and evaluate the performance.\n",
    "\n",
    "4. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain **the code** and **the output after execution**.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "5. Upload this .HTML file to your Google Drive, Dropbox, or your Github repo.  (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "6. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM2/HM2.html\n",
    "\n",
    "\n",
    "## Grading criteria:\n",
    "\n",
    "1. When computing the ```gradient``` and ```objective function value``` using a batch of samples, use **matrix-vector multiplication** rather than a FOR LOOP of **vector-vector multiplications**.\n",
    "\n",
    "2. Plot ```objective function value``` against ```epochs```. In the plot, compare GD, SGD, and MB-SGD (with $b=8$ and $b=64$). The plot must look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data processing\n",
    "\n",
    "- Download the Diabete dataset from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes\n",
    "- Load the data using sklearn.\n",
    "- Preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (768, 8)\n",
      "Shape of y: (768,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy\n",
    "\n",
    "x_sparse, y = datasets.load_svmlight_file('diabetes')\n",
    "x = x_sparse.todense()\n",
    "\n",
    "print('Shape of x: ' + str(x.shape))\n",
    "print('Shape of y: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Partition to training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 8)\n",
      "Shape of x_test: (128, 8)\n",
      "Shape of y_train: (640, 1)\n",
      "Shape of y_test: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "# partition the data to training and test sets\n",
    "n = x.shape[0]\n",
    "n_train = 640\n",
    "n_test = n - n_train\n",
    "\n",
    "rand_indices = numpy.random.permutation(n)\n",
    "train_indices = rand_indices[0:n_train]\n",
    "test_indices = rand_indices[n_train:n]\n",
    "\n",
    "x_train = x[train_indices, :]\n",
    "x_test = x[test_indices, :]\n",
    "y_train = y[train_indices].reshape(n_train, 1)\n",
    "y_test = y[test_indices].reshape(n_test, 1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the standardization to trainsform both training and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean = \n",
      "[[-0.20431559  0.06369718 -0.08417363  0.21243742  0.03708194 -0.0354605\n",
      "   0.02255901 -0.21633785]]\n",
      "test std = \n",
      "[[0.91642242 0.9869856  1.00304103 0.89261679 0.95777534 1.16504387\n",
      "  1.01422498 0.87249145]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "import numpy\n",
    "\n",
    "# calculate mu and sig using the training set\n",
    "d = x_train.shape[1]\n",
    "mu = numpy.mean(x_train, axis=0).reshape(1, d)\n",
    "sig = numpy.std(x_train, axis=0).reshape(1, d)\n",
    "\n",
    "# transform the training features\n",
    "x_train = (x_train - mu) / (sig + 1E-6)\n",
    "\n",
    "# transform the test features\n",
    "x_test = (x_test - mu) / (sig + 1E-6)\n",
    "\n",
    "print('test mean = ')\n",
    "print(numpy.mean(x_test, axis=0))\n",
    "\n",
    "print('test std = ')\n",
    "print(numpy.std(x_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Add a dimension of all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 9)\n",
      "Shape of x_test: (128, 9)\n"
     ]
    }
   ],
   "source": [
    "n_train, d = x_train.shape\n",
    "x_train = numpy.concatenate((x_train, numpy.ones((n_train, 1))), axis=1)\n",
    "\n",
    "n_test, d = x_test.shape\n",
    "x_test = numpy.concatenate((x_test, numpy.ones((n_test, 1))), axis=1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic regression model\n",
    "\n",
    "The objective function is $Q (w; X, y) = \\frac{1}{n} \\sum_{i=1}^n \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective function value\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     objective function value (scalar)\n",
    "def objective(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(-yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.log(1 + vec1) # n-by-1 matrix\n",
    "    loss = numpy.mean(vec2) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    return loss + reg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial objective function value = 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "# initialize w\n",
    "d = x_train.shape[1]\n",
    "w = numpy.zeros((d, 1))\n",
    "\n",
    "# evaluate the objective function value at w\n",
    "lam = 1E-6\n",
    "objval0 = objective(w, x_train, y_train, lam)\n",
    "print('Initial objective function value = ' + str(objval0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Numerical optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient at $w$ is $g = - \\frac{1}{n} \\sum_{i=1}^n \\frac{y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gradient\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     g: g: d-by-1 matrix, full gradient\n",
    "def gradient(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.divide(yx, 1+vec1) # n-by-d matrix\n",
    "    vec3 = -numpy.mean(vec2, axis=0).reshape(d, 1) # d-by-1 matrix\n",
    "    g = vec3 + lam * w\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_iter: integer, the maximal iterations\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: d-by-1 matrix, the solution\n",
    "#     objvals: a record of each iteration's objective value\n",
    "def grad_descent(x, y, lam, stepsize, max_iter=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_iter) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_iter):\n",
    "        objval = objective(w, x, y, lam)\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at t=' + str(t) + ' is ' + str(objval))\n",
    "        g = gradient(w, x, y, lam)\n",
    "        w -= stepsize * g\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at t=0 is 0.6931471805599453\n",
      "Objective value at t=1 is 0.5807033173373405\n",
      "Objective value at t=2 is 0.5358713049727934\n",
      "Objective value at t=3 is 0.5118227393482404\n",
      "Objective value at t=4 is 0.49676088306249744\n",
      "Objective value at t=5 is 0.48649118940897296\n",
      "Objective value at t=6 is 0.4791145598071483\n",
      "Objective value at t=7 is 0.4736275851601962\n",
      "Objective value at t=8 is 0.46944218406436256\n",
      "Objective value at t=9 is 0.4661878740275751\n",
      "Objective value at t=10 is 0.4636187880447292\n",
      "Objective value at t=11 is 0.4615652947371097\n",
      "Objective value at t=12 is 0.45990678604102364\n",
      "Objective value at t=13 is 0.4585554175114803\n",
      "Objective value at t=14 is 0.457445922544377\n",
      "Objective value at t=15 is 0.45652898743436016\n",
      "Objective value at t=16 is 0.45576680931864294\n",
      "Objective value at t=17 is 0.455130041644702\n",
      "Objective value at t=18 is 0.4545956482976352\n",
      "Objective value at t=19 is 0.4541453678683289\n",
      "Objective value at t=20 is 0.4537645964880712\n",
      "Objective value at t=21 is 0.45344156322578166\n",
      "Objective value at t=22 is 0.45316671339524467\n",
      "Objective value at t=23 is 0.45293224183227504\n",
      "Objective value at t=24 is 0.4527317358216633\n",
      "Objective value at t=25 is 0.45255989919179596\n",
      "Objective value at t=26 is 0.4524123371802348\n",
      "Objective value at t=27 is 0.4522853872788198\n",
      "Objective value at t=28 is 0.4521759852062063\n",
      "Objective value at t=29 is 0.4520815579594271\n",
      "Objective value at t=30 is 0.45199993791500875\n",
      "Objective value at t=31 is 0.4519292934200008\n",
      "Objective value at t=32 is 0.4518680723943738\n",
      "Objective value at t=33 is 0.4518149562690997\n",
      "Objective value at t=34 is 0.45176882218587233\n",
      "Objective value at t=35 is 0.45172871183914504\n",
      "Objective value at t=36 is 0.45169380568760176\n",
      "Objective value at t=37 is 0.45166340152813067\n",
      "Objective value at t=38 is 0.45163689663098955\n",
      "Objective value at t=39 is 0.45161377279491194\n",
      "Objective value at t=40 is 0.45159358380628034\n",
      "Objective value at t=41 is 0.45157594488530234\n",
      "Objective value at t=42 is 0.4515605237804406\n",
      "Objective value at t=43 is 0.4515470332347448\n",
      "Objective value at t=44 is 0.4515352245977165\n",
      "Objective value at t=45 is 0.4515248823965459\n",
      "Objective value at t=46 is 0.4515158197130814\n",
      "Objective value at t=47 is 0.4515078742392796\n",
      "Objective value at t=48 is 0.45150090490540623\n",
      "Objective value at t=49 is 0.4514947889928653\n",
      "Objective value at t=50 is 0.4514894196579975\n",
      "Objective value at t=51 is 0.4514847038051061\n",
      "Objective value at t=52 is 0.4514805602568309\n",
      "Objective value at t=53 is 0.45147691817816293\n",
      "Objective value at t=54 is 0.4514737157171947\n",
      "Objective value at t=55 is 0.45147089883138153\n",
      "Objective value at t=56 is 0.4514684202728285\n",
      "Objective value at t=57 is 0.45146623871010705\n",
      "Objective value at t=58 is 0.4514643179674479\n",
      "Objective value at t=59 is 0.4514626263649796\n",
      "Objective value at t=60 is 0.45146113614605965\n",
      "Objective value at t=61 is 0.4514598229797688\n",
      "Objective value at t=62 is 0.45145866552833774\n",
      "Objective value at t=63 is 0.45145764507073527\n",
      "Objective value at t=64 is 0.45145674517487605\n",
      "Objective value at t=65 is 0.45145595141196515\n",
      "Objective value at t=66 is 0.4514552511073889\n",
      "Objective value at t=67 is 0.4514546331233359\n",
      "Objective value at t=68 is 0.45145408766898737\n",
      "Objective value at t=69 is 0.4514536061346806\n",
      "Objective value at t=70 is 0.45145318094693565\n",
      "Objective value at t=71 is 0.4514528054416524\n",
      "Objective value at t=72 is 0.4514524737531395\n",
      "Objective value at t=73 is 0.451452180716953\n",
      "Objective value at t=74 is 0.45145192178478394\n",
      "Objective value at t=75 is 0.4514516929498665\n",
      "Objective value at t=76 is 0.4514514906815774\n",
      "Objective value at t=77 is 0.45145131186806975\n",
      "Objective value at t=78 is 0.45145115376593425\n",
      "Objective value at t=79 is 0.4514510139560087\n",
      "Objective value at t=80 is 0.4514508903045711\n",
      "Objective value at t=81 is 0.4514507809292477\n",
      "Objective value at t=82 is 0.45145068416905315\n",
      "Objective value at t=83 is 0.4514505985580522\n",
      "Objective value at t=84 is 0.4514505228021985\n",
      "Objective value at t=85 is 0.4514504557589607\n",
      "Objective value at t=86 is 0.45145039641939505\n",
      "Objective value at t=87 is 0.45145034389236544\n",
      "Objective value at t=88 is 0.45145029739065107\n",
      "Objective value at t=89 is 0.45145025621871165\n",
      "Objective value at t=90 is 0.4514502197619093\n",
      "Objective value at t=91 is 0.45145018747701293\n",
      "Objective value at t=92 is 0.45145015888382795\n",
      "Objective value at t=93 is 0.451450133557819\n",
      "Objective value at t=94 is 0.45145011112360356\n",
      "Objective value at t=95 is 0.4514500912492152\n",
      "Objective value at t=96 is 0.4514500736410415\n",
      "Objective value at t=97 is 0.4514500580393591\n",
      "Objective value at t=98 is 0.45145004421439244\n",
      "Objective value at t=99 is 0.45145003196283545\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 1.0\n",
    "w, objvals_gd = grad_descent(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Stochastic gradient descent (SGD)\n",
    "\n",
    "Define $Q_i (w) = \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $.\n",
    "\n",
    "The stochastic gradient at $w$ is $g_i = \\frac{\\partial Q_i }{ \\partial w} = -\\frac{y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_i and the gradient of Q_i\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: 1-by-d matrix\n",
    "#     yi: scalar\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def stochastic_objective_gradient(w, xi, yi, lam):\n",
    "    d = xi.shape[0]\n",
    "    yx = yi * xi # 1-by-d matrix\n",
    "    yxw = float(numpy.dot(yx, w)) # scalar\n",
    "    \n",
    "    # calculate objective function Q_i\n",
    "    loss = numpy.log(1 + numpy.exp(-yxw)) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    obj = loss + reg\n",
    "    \n",
    "    # calculate stochastic gradient\n",
    "    g_loss = -yx.T / (1 + numpy.exp(yxw)) # d-by-1 matrix\n",
    "    g = g_loss + lam * w # d-by-1 matrix\n",
    "    \n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "def sgd(x, y, lam, stepsize, max_epoch=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_epoch) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_epoch):\n",
    "        # randomly shuffle the samples\n",
    "        rand_indices = numpy.random.permutation(n)\n",
    "        x_rand = x[rand_indices, :]\n",
    "        y_rand = y[rand_indices, :]\n",
    "        \n",
    "        objval = 0 # accumulate the objective values\n",
    "        for i in range(n):\n",
    "            xi = x_rand[i, :] # 1-by-d matrix\n",
    "            yi = float(y_rand[i, :]) # scalar\n",
    "            obj, g = stochastic_objective_gradient(w, xi, yi, lam)\n",
    "            objval += obj\n",
    "            w -= stepsize * g\n",
    "        \n",
    "        stepsize *= 0.9 # decrease step size\n",
    "        objval /= n\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at epoch t=' + str(t) + ' is ' + str(objval))\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at epoch t=0 is 0.5143082279814007\n",
      "Objective value at epoch t=1 is 0.47782390521538975\n",
      "Objective value at epoch t=2 is 0.487407944674927\n",
      "Objective value at epoch t=3 is 0.4824305760372378\n",
      "Objective value at epoch t=4 is 0.47512017816313434\n",
      "Objective value at epoch t=5 is 0.48185230646553556\n",
      "Objective value at epoch t=6 is 0.47865531179848997\n",
      "Objective value at epoch t=7 is 0.4793184975101714\n",
      "Objective value at epoch t=8 is 0.46940494967469215\n",
      "Objective value at epoch t=9 is 0.46855627768661307\n",
      "Objective value at epoch t=10 is 0.47457333703870247\n",
      "Objective value at epoch t=11 is 0.4688871356668461\n",
      "Objective value at epoch t=12 is 0.46932415833046387\n",
      "Objective value at epoch t=13 is 0.4659156820433797\n",
      "Objective value at epoch t=14 is 0.4655375650217869\n",
      "Objective value at epoch t=15 is 0.4635647560866514\n",
      "Objective value at epoch t=16 is 0.46314693110567895\n",
      "Objective value at epoch t=17 is 0.46057088470973107\n",
      "Objective value at epoch t=18 is 0.46022871385551883\n",
      "Objective value at epoch t=19 is 0.45963852756272494\n",
      "Objective value at epoch t=20 is 0.4582989164569694\n",
      "Objective value at epoch t=21 is 0.4589488615069561\n",
      "Objective value at epoch t=22 is 0.45726040915582933\n",
      "Objective value at epoch t=23 is 0.45706971857488526\n",
      "Objective value at epoch t=24 is 0.45669928098054696\n",
      "Objective value at epoch t=25 is 0.45615223033287966\n",
      "Objective value at epoch t=26 is 0.45585757288203493\n",
      "Objective value at epoch t=27 is 0.45522910686873097\n",
      "Objective value at epoch t=28 is 0.45491116789072494\n",
      "Objective value at epoch t=29 is 0.45472611650509387\n",
      "Objective value at epoch t=30 is 0.4543383079689061\n",
      "Objective value at epoch t=31 is 0.45400459563162165\n",
      "Objective value at epoch t=32 is 0.4538435951886335\n",
      "Objective value at epoch t=33 is 0.45356190635590093\n",
      "Objective value at epoch t=34 is 0.45330473829383894\n",
      "Objective value at epoch t=35 is 0.4531847322691645\n",
      "Objective value at epoch t=36 is 0.45302256871961744\n",
      "Objective value at epoch t=37 is 0.4528584536770131\n",
      "Objective value at epoch t=38 is 0.45273799847592766\n",
      "Objective value at epoch t=39 is 0.4526055190536458\n",
      "Objective value at epoch t=40 is 0.4525018408722124\n",
      "Objective value at epoch t=41 is 0.45238395638619905\n",
      "Objective value at epoch t=42 is 0.4522863183213944\n",
      "Objective value at epoch t=43 is 0.4522158981092946\n",
      "Objective value at epoch t=44 is 0.4521337843864088\n",
      "Objective value at epoch t=45 is 0.4520729966729797\n",
      "Objective value at epoch t=46 is 0.452004779475792\n",
      "Objective value at epoch t=47 is 0.4519495300298792\n",
      "Objective value at epoch t=48 is 0.4519029955220141\n",
      "Objective value at epoch t=49 is 0.45185806999783884\n",
      "Objective value at epoch t=50 is 0.4518185462154329\n",
      "Objective value at epoch t=51 is 0.4517815197483821\n",
      "Objective value at epoch t=52 is 0.4517476769659125\n",
      "Objective value at epoch t=53 is 0.45171895391924444\n",
      "Objective value at epoch t=54 is 0.45169128806577225\n",
      "Objective value at epoch t=55 is 0.45166804316032305\n",
      "Objective value at epoch t=56 is 0.45164536199606636\n",
      "Objective value at epoch t=57 is 0.4516266806085857\n",
      "Objective value at epoch t=58 is 0.4516087996402005\n",
      "Objective value at epoch t=59 is 0.45159325631433367\n",
      "Objective value at epoch t=60 is 0.45157868991053907\n",
      "Objective value at epoch t=61 is 0.45156607634083434\n",
      "Objective value at epoch t=62 is 0.4515544481441992\n",
      "Objective value at epoch t=63 is 0.4515439563871704\n",
      "Objective value at epoch t=64 is 0.45153474895337914\n",
      "Objective value at epoch t=65 is 0.45152618131663314\n",
      "Objective value at epoch t=66 is 0.45151861889822953\n",
      "Objective value at epoch t=67 is 0.45151173975314035\n",
      "Objective value at epoch t=68 is 0.4515056012239797\n",
      "Objective value at epoch t=69 is 0.45150009155860016\n",
      "Objective value at epoch t=70 is 0.4514950870819674\n",
      "Objective value at epoch t=71 is 0.45149061090412124\n",
      "Objective value at epoch t=72 is 0.45148655907870394\n",
      "Objective value at epoch t=73 is 0.45148286878357274\n",
      "Objective value at epoch t=74 is 0.4514796362725534\n",
      "Objective value at epoch t=75 is 0.45147668993672657\n",
      "Objective value at epoch t=76 is 0.4514740319228087\n",
      "Objective value at epoch t=77 is 0.45147164875740253\n",
      "Objective value at epoch t=78 is 0.4514694942088096\n",
      "Objective value at epoch t=79 is 0.4514675614149658\n",
      "Objective value at epoch t=80 is 0.45146581332724267\n",
      "Objective value at epoch t=81 is 0.45146424471888374\n",
      "Objective value at epoch t=82 is 0.4514628351458095\n",
      "Objective value at epoch t=83 is 0.4514615677366464\n",
      "Objective value at epoch t=84 is 0.45146042257745156\n",
      "Objective value at epoch t=85 is 0.4514593920575892\n",
      "Objective value at epoch t=86 is 0.45145846727030625\n",
      "Objective value at epoch t=87 is 0.4514576341668615\n",
      "Objective value at epoch t=88 is 0.45145688392795585\n",
      "Objective value at epoch t=89 is 0.4514562084808701\n",
      "Objective value at epoch t=90 is 0.4514556006143409\n",
      "Objective value at epoch t=91 is 0.4514550536794779\n",
      "Objective value at epoch t=92 is 0.4514545606005146\n",
      "Objective value at epoch t=93 is 0.45145411725807383\n",
      "Objective value at epoch t=94 is 0.4514537191801861\n",
      "Objective value at epoch t=95 is 0.4514533603252107\n",
      "Objective value at epoch t=96 is 0.4514530370377609\n",
      "Objective value at epoch t=97 is 0.45145274639211863\n",
      "Objective value at epoch t=98 is 0.4514524847348137\n",
      "Objective value at epoch t=99 is 0.4514522491919468\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 0.1\n",
    "w, objvals_sgd = sgd(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare GD with SGD\n",
    "\n",
    "Plot objective function values against epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "\n",
    "epochs_gd = range(len(objvals_gd))\n",
    "epochs_sgd = range(len(objvals_sgd))\n",
    "\n",
    "line0, = plt.plot(epochs_gd, objvals_gd, '--b', LineWidth=4)\n",
    "line1, = plt.plot(epochs_sgd, objvals_sgd, '-r', LineWidth=2)\n",
    "plt.xlabel('Epochs', FontSize=20)\n",
    "plt.ylabel('Objective Value', FontSize=20)\n",
    "plt.xticks(FontSize=16)\n",
    "plt.yticks(FontSize=16)\n",
    "plt.legend([line0, line1], ['GD', 'SGD'], fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('compare_gd_sgd.pdf', format='pdf', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class label\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     X: m-by-d matrix\n",
    "# Return:\n",
    "#     f: m-by-1 matrix, the predictions\n",
    "def predict(w, X):\n",
    "    xw = numpy.dot(X, w)\n",
    "    f = numpy.sign(xw)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error is 0.2171875\n"
     ]
    }
   ],
   "source": [
    "# evaluate training error\n",
    "f_train = predict(w, x_train)\n",
    "diff = numpy.abs(f_train - y_train) / 2\n",
    "error_train = numpy.mean(diff)\n",
    "print('Training classification error is ' + str(error_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test classification error is 0.2734375\n"
     ]
    }
   ],
   "source": [
    "# evaluate test error\n",
    "f_test = predict(w, x_test)\n",
    "diff = numpy.abs(f_test - y_test) / 2\n",
    "error_test = numpy.mean(diff)\n",
    "print('Test classification error is ' + str(error_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Mini-batch SGD (fill the code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Compute the objective $Q_I$ and its gradient using a batch of samples\n",
    "\n",
    "Define $Q_I (w) = \\frac{1}{b} \\sum_{i \\in I} \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $, where $I$ is a set containing $b$ indices randomly drawn from $\\{ 1, \\cdots , n \\}$ without replacement.\n",
    "\n",
    "The stochastic gradient at $w$ is $g_I = \\frac{\\partial Q_I }{ \\partial w} = \\frac{1}{b} \\sum_{i \\in I} \\frac{- y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_I and the gradient of Q_I\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: b-by-d matrix\n",
    "#     yi: b-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     b: integer, the batch size\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def mb_stochastic_objective_gradient(w, xi, yi, lam, b):\n",
    "    # Follow the implementation of stochastic_objective_gradient\n",
    "    # Use matrix-vector multiplication; do not use FOR LOOP of vector-vector multiplications\n",
    "    obj = objective(w,xi,yi,lam)\n",
    "    g = gradient(w,xi,yi,lam)\n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Implement mini-batch SGD\n",
    "\n",
    "Hints:\n",
    "1. In every epoch, randomly permute the $n$ samples (just like SGD).\n",
    "2. Each epoch has $\\frac{n}{b}$ iterations. In every iteration, use $b$ samples, and compute the gradient and objective using the ``mb_stochastic_objective_gradient`` function. In the next iteration, use the next $b$ samples, and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-Batch SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     b: integer, the batch size\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "def mb_sgd(x, y, lam, b, stepsize, max_epoch=100, w=None):\n",
    "    # Fill the function\n",
    "    # Follow the implementation of sgd\n",
    "    # Record one objective value per epoch (not per iteration!)\n",
    "    n,d = x.shape\n",
    "    objvals = []\n",
    "    \n",
    "    chunks = n // b\n",
    "    # in the case of bad chunk size\n",
    "    if n % b != 0:\n",
    "        chunks += 1\n",
    "    \n",
    "    # intialization to 0\n",
    "    if w == None:\n",
    "        w = numpy.zeros((d,1))\n",
    "    # iterate through max_epochs\n",
    "    for t in range(max_epoch):\n",
    "        # randomly shuffle the training data and labels\n",
    "        epoch_obj = 0\n",
    "        rand_indices = numpy.random.permutation(n)\n",
    "        x_rand = x[rand_indices, :]\n",
    "        y_rand = y[rand_indices, :]\n",
    "        # divide into minibatches and get the gradient and objval\n",
    "        for i in range(chunks):\n",
    "            # start and stop for the batch\n",
    "            start = i * b\n",
    "            end = (i+1) * b\n",
    "            # acquire a minibatch\n",
    "            xi = x_rand[start:end,:]\n",
    "            yi = y_rand[start:end,:]\n",
    "            \n",
    "            obj, gradient = mb_stochastic_objective_gradient(w,xi,yi,lam,b)\n",
    "            \n",
    "            #update obj_val and gradient\n",
    "            epoch_obj += obj\n",
    "            w -= stepsize * gradient\n",
    "        epoch_obj /= chunks\n",
    "        objvals.append(epoch_obj)\n",
    "        print('Objective value at epoch t=' + str(t) + ' is ' + str(epoch_obj))\n",
    "        \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Run MB-SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at epoch t=0 is 0.545146050993036\n",
      "Objective value at epoch t=1 is 0.4876431722483218\n",
      "Objective value at epoch t=2 is 0.4810078937998382\n",
      "Objective value at epoch t=3 is 0.4803555203875585\n",
      "Objective value at epoch t=4 is 0.48072948898368956\n",
      "Objective value at epoch t=5 is 0.4795427693388176\n",
      "Objective value at epoch t=6 is 0.478945752523269\n",
      "Objective value at epoch t=7 is 0.4781340121961809\n",
      "Objective value at epoch t=8 is 0.4796519257286757\n",
      "Objective value at epoch t=9 is 0.4793390641227691\n",
      "Objective value at epoch t=10 is 0.47919085715328985\n",
      "Objective value at epoch t=11 is 0.47950173298196336\n",
      "Objective value at epoch t=12 is 0.48039057634537324\n",
      "Objective value at epoch t=13 is 0.4788764794067748\n",
      "Objective value at epoch t=14 is 0.48050411774840757\n",
      "Objective value at epoch t=15 is 0.47994679316459826\n",
      "Objective value at epoch t=16 is 0.47953140062948696\n",
      "Objective value at epoch t=17 is 0.4800610291651822\n",
      "Objective value at epoch t=18 is 0.47814226196646137\n",
      "Objective value at epoch t=19 is 0.48013124221200065\n",
      "Objective value at epoch t=20 is 0.4800706966810043\n",
      "Objective value at epoch t=21 is 0.4788683611564504\n",
      "Objective value at epoch t=22 is 0.4792468746560202\n",
      "Objective value at epoch t=23 is 0.4801358693033443\n",
      "Objective value at epoch t=24 is 0.4790856008466277\n",
      "Objective value at epoch t=25 is 0.4801466424782153\n",
      "Objective value at epoch t=26 is 0.4808377400238689\n",
      "Objective value at epoch t=27 is 0.4805076572379858\n",
      "Objective value at epoch t=28 is 0.48092858200376404\n",
      "Objective value at epoch t=29 is 0.47956668825380494\n",
      "Objective value at epoch t=30 is 0.4781901245417215\n",
      "Objective value at epoch t=31 is 0.4794347646030473\n",
      "Objective value at epoch t=32 is 0.4782414648206352\n",
      "Objective value at epoch t=33 is 0.4803091746440559\n",
      "Objective value at epoch t=34 is 0.47885930320742737\n",
      "Objective value at epoch t=35 is 0.47988895295027206\n",
      "Objective value at epoch t=36 is 0.47979711054029534\n",
      "Objective value at epoch t=37 is 0.4796826188328624\n",
      "Objective value at epoch t=38 is 0.4807072265717177\n",
      "Objective value at epoch t=39 is 0.47957939775913666\n",
      "Objective value at epoch t=40 is 0.4801502344519705\n",
      "Objective value at epoch t=41 is 0.4803653413413366\n",
      "Objective value at epoch t=42 is 0.4796907590736371\n",
      "Objective value at epoch t=43 is 0.4792054379147041\n",
      "Objective value at epoch t=44 is 0.4790228866849585\n",
      "Objective value at epoch t=45 is 0.4792954297673696\n",
      "Objective value at epoch t=46 is 0.47879202276600574\n",
      "Objective value at epoch t=47 is 0.48058180003458706\n",
      "Objective value at epoch t=48 is 0.4798687440291876\n",
      "Objective value at epoch t=49 is 0.48008270313985557\n",
      "Objective value at epoch t=50 is 0.47991378123772793\n",
      "Objective value at epoch t=51 is 0.47866926681766575\n",
      "Objective value at epoch t=52 is 0.4800683446049286\n",
      "Objective value at epoch t=53 is 0.48143931275296453\n",
      "Objective value at epoch t=54 is 0.4782578726720022\n",
      "Objective value at epoch t=55 is 0.47874374108205114\n",
      "Objective value at epoch t=56 is 0.4797996777348531\n",
      "Objective value at epoch t=57 is 0.4796989079039645\n",
      "Objective value at epoch t=58 is 0.47862508832363293\n",
      "Objective value at epoch t=59 is 0.4789310462374206\n",
      "Objective value at epoch t=60 is 0.4794647103331037\n",
      "Objective value at epoch t=61 is 0.47966336645564206\n",
      "Objective value at epoch t=62 is 0.47954302753050726\n",
      "Objective value at epoch t=63 is 0.4791185984467347\n",
      "Objective value at epoch t=64 is 0.4803022911631986\n",
      "Objective value at epoch t=65 is 0.4794806465547782\n",
      "Objective value at epoch t=66 is 0.4776797566240999\n",
      "Objective value at epoch t=67 is 0.47942893427023836\n",
      "Objective value at epoch t=68 is 0.4810395510131283\n",
      "Objective value at epoch t=69 is 0.4795223195761348\n",
      "Objective value at epoch t=70 is 0.4783050718334376\n",
      "Objective value at epoch t=71 is 0.47915151471819656\n",
      "Objective value at epoch t=72 is 0.4796714252373507\n",
      "Objective value at epoch t=73 is 0.4793974883538656\n",
      "Objective value at epoch t=74 is 0.4805874101594174\n",
      "Objective value at epoch t=75 is 0.48073208514946497\n",
      "Objective value at epoch t=76 is 0.4802902413016164\n",
      "Objective value at epoch t=77 is 0.47989604780359973\n",
      "Objective value at epoch t=78 is 0.4799243241968777\n",
      "Objective value at epoch t=79 is 0.47885268406349973\n",
      "Objective value at epoch t=80 is 0.4788567935863394\n",
      "Objective value at epoch t=81 is 0.48031886529977613\n",
      "Objective value at epoch t=82 is 0.4801777106936666\n",
      "Objective value at epoch t=83 is 0.47946982130291194\n",
      "Objective value at epoch t=84 is 0.4801969916352604\n",
      "Objective value at epoch t=85 is 0.47958841116322015\n",
      "Objective value at epoch t=86 is 0.4794959405838727\n",
      "Objective value at epoch t=87 is 0.47981798949479415\n",
      "Objective value at epoch t=88 is 0.4798669307910483\n",
      "Objective value at epoch t=89 is 0.48037496819423753\n",
      "Objective value at epoch t=90 is 0.4793650833280013\n",
      "Objective value at epoch t=91 is 0.48005181525844864\n",
      "Objective value at epoch t=92 is 0.48012696969397856\n",
      "Objective value at epoch t=93 is 0.47872306981353707\n",
      "Objective value at epoch t=94 is 0.479350246429113\n",
      "Objective value at epoch t=95 is 0.4799280757671297\n",
      "Objective value at epoch t=96 is 0.47827355809521804\n",
      "Objective value at epoch t=97 is 0.47942725744818304\n",
      "Objective value at epoch t=98 is 0.4810714920335504\n",
      "Objective value at epoch t=99 is 0.4807009960200192\n"
     ]
    }
   ],
   "source": [
    "# MB-SGD with batch size b=8\n",
    "lam = 1E-6 # do not change\n",
    "b = 8 # do not change\n",
    "stepsize = 0.1 # you must tune this parameter\n",
    "\n",
    "w, objvals_mbsgd8 = mb_sgd(x_train, y_train, lam, b, stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MB-SGD with batch size b=64\n",
    "lam = 1E-6 # do not change\n",
    "b = 64 # do not change\n",
    "stepsize = 0.1 # you must tune this parameter\n",
    "\n",
    "w, objvals_mbsgd64 = mb_sgd(x_train, y_train, lam, b, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Plot and compare GD, SGD, and MB-SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to compare the following algorithms:\n",
    "\n",
    "- Gradient descent (GD)\n",
    "\n",
    "- SGD\n",
    "\n",
    "- MB-SGD with b=8\n",
    "\n",
    "- MB-SGD with b=64\n",
    "\n",
    "Follow the code in Section 4 to plot ```objective function value``` against ```epochs```. There should be four curves in the plot; each curve corresponds to one algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Logistic regression with $\\ell_2$-norm regularization is a strongly convex optimization problem. All the algorithms will converge to the same solution. **In the end, the ``objective function value`` of the 4 algorithms will be the same. If not the same, your implementation must be wrong. Do NOT submit wrong code and wrong result!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 4 curves:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
