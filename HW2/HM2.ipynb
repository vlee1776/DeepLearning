{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HM2: Numerical Optimization for Logistic Regression.\n",
    "\n",
    "### Name: Vincent Lee\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read the lecture note: [click here](https://github.com/wangshusen/DeepLearning/blob/master/LectureNotes/Logistic/paper/logistic.pdf)\n",
    "\n",
    "2. Read, complete, and run my code.\n",
    "\n",
    "3. **Implement mini-batch SGD** and evaluate the performance.\n",
    "\n",
    "4. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain **the code** and **the output after execution**.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "5. Upload this .HTML file to your Google Drive, Dropbox, or your Github repo.  (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "6. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM2/HM2.html\n",
    "\n",
    "\n",
    "## Grading criteria:\n",
    "\n",
    "1. When computing the ```gradient``` and ```objective function value``` using a batch of samples, use **matrix-vector multiplication** rather than a FOR LOOP of **vector-vector multiplications**.\n",
    "\n",
    "2. Plot ```objective function value``` against ```epochs```. In the plot, compare GD, SGD, and MB-SGD (with $b=8$ and $b=64$). The plot must look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data processing\n",
    "\n",
    "- Download the Diabete dataset from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes\n",
    "- Load the data using sklearn.\n",
    "- Preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (768, 8)\n",
      "Shape of y: (768,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy\n",
    "\n",
    "x_sparse, y = datasets.load_svmlight_file('diabetes')\n",
    "x = x_sparse.todense()\n",
    "\n",
    "print('Shape of x: ' + str(x.shape))\n",
    "print('Shape of y: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Partition to training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 8)\n",
      "Shape of x_test: (128, 8)\n",
      "Shape of y_train: (640, 1)\n",
      "Shape of y_test: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "# partition the data to training and test sets\n",
    "n = x.shape[0]\n",
    "n_train = 640\n",
    "n_test = n - n_train\n",
    "\n",
    "rand_indices = numpy.random.permutation(n)\n",
    "train_indices = rand_indices[0:n_train]\n",
    "test_indices = rand_indices[n_train:n]\n",
    "\n",
    "x_train = x[train_indices, :]\n",
    "x_test = x[test_indices, :]\n",
    "y_train = y[train_indices].reshape(n_train, 1)\n",
    "y_test = y[test_indices].reshape(n_test, 1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the standardization to trainsform both training and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean = \n",
      "[[-0.08854186 -0.08430218  0.07027727 -0.02524652 -0.05923962  0.00594898\n",
      "  -0.07147775 -0.23235968]]\n",
      "test std = \n",
      "[[0.92661667 1.0140942  0.89124873 0.89383095 0.81009921 0.80920254\n",
      "  0.80184708 0.73693754]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "import numpy\n",
    "\n",
    "# calculate mu and sig using the training set\n",
    "d = x_train.shape[1]\n",
    "mu = numpy.mean(x_train, axis=0).reshape(1, d)\n",
    "sig = numpy.std(x_train, axis=0).reshape(1, d)\n",
    "\n",
    "# transform the training features\n",
    "x_train = (x_train - mu) / (sig + 1E-6)\n",
    "\n",
    "# transform the test features\n",
    "x_test = (x_test - mu) / (sig + 1E-6)\n",
    "\n",
    "print('test mean = ')\n",
    "print(numpy.mean(x_test, axis=0))\n",
    "\n",
    "print('test std = ')\n",
    "print(numpy.std(x_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Add a dimension of all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 9)\n",
      "Shape of x_test: (128, 9)\n"
     ]
    }
   ],
   "source": [
    "n_train, d = x_train.shape\n",
    "x_train = numpy.concatenate((x_train, numpy.ones((n_train, 1))), axis=1)\n",
    "\n",
    "n_test, d = x_test.shape\n",
    "x_test = numpy.concatenate((x_test, numpy.ones((n_test, 1))), axis=1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic regression model\n",
    "\n",
    "The objective function is $Q (w; X, y) = \\frac{1}{n} \\sum_{i=1}^n \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective function value\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     objective function value (scalar)\n",
    "def objective(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(-yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.log(1 + vec1) # n-by-1 matrix\n",
    "    loss = numpy.mean(vec2) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    return loss + reg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial objective function value = 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "# initialize w\n",
    "d = x_train.shape[1]\n",
    "w = numpy.zeros((d, 1))\n",
    "\n",
    "# evaluate the objective function value at w\n",
    "lam = 1E-6\n",
    "objval0 = objective(w, x_train, y_train, lam)\n",
    "print('Initial objective function value = ' + str(objval0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Numerical optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient at $w$ is $g = - \\frac{1}{n} \\sum_{i=1}^n \\frac{y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gradient\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     g: g: d-by-1 matrix, full gradient\n",
    "def gradient(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.divide(yx, 1+vec1) # n-by-d matrix\n",
    "    vec3 = -numpy.mean(vec2, axis=0).reshape(d, 1) # d-by-1 matrix\n",
    "    g = vec3 + lam * w\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_iter: integer, the maximal iterations\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: d-by-1 matrix, the solution\n",
    "#     objvals: a record of each iteration's objective value\n",
    "def grad_descent(x, y, lam, stepsize, max_iter=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_iter) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_iter):\n",
    "        objval = objective(w, x, y, lam)\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at t=' + str(t) + ' is ' + str(objval))\n",
    "        g = gradient(w, x, y, lam)\n",
    "        w -= stepsize * g\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at t=0 is 0.6931471805599453\n",
      "Objective value at t=1 is 0.5952718469849477\n",
      "Objective value at t=2 is 0.5546421858617253\n",
      "Objective value at t=3 is 0.5326023618073956\n",
      "Objective value at t=4 is 0.5187918109550153\n",
      "Objective value at t=5 is 0.5094161672165941\n",
      "Objective value at t=6 is 0.5027270700226505\n",
      "Objective value at t=7 is 0.4977904699129754\n",
      "Objective value at t=8 is 0.4940557871543751\n",
      "Objective value at t=9 is 0.4911757077203414\n",
      "Objective value at t=10 is 0.48892019995911845\n",
      "Objective value at t=11 is 0.4871312287136751\n",
      "Objective value at t=12 is 0.48569705790753903\n",
      "Objective value at t=13 is 0.4845368170943795\n",
      "Objective value at t=14 is 0.4835908160939777\n",
      "Objective value at t=15 is 0.4828142513002776\n",
      "Objective value at t=16 is 0.4821729979083524\n",
      "Objective value at t=17 is 0.4816407286819068\n",
      "Objective value at t=18 is 0.4811969000265447\n",
      "Objective value at t=19 is 0.4808253185941168\n",
      "Objective value at t=20 is 0.4805131044690396\n",
      "Objective value at t=21 is 0.4802499302074173\n",
      "Objective value at t=22 is 0.4800274548905177\n",
      "Objective value at t=23 is 0.47983889809251273\n",
      "Objective value at t=24 is 0.47967871559751146\n",
      "Objective value at t=25 is 0.47954235003995893\n",
      "Objective value at t=26 is 0.47942603735561695\n",
      "Objective value at t=27 is 0.47932665525360735\n",
      "Objective value at t=28 is 0.4792416036434512\n",
      "Objective value at t=29 is 0.47916870958819613\n",
      "Objective value at t=30 is 0.47910615124446987\n",
      "Objective value at t=31 is 0.4790523966194279\n",
      "Objective value at t=32 is 0.47900615397680857\n",
      "Objective value at t=33 is 0.47896633146520334\n",
      "Objective value at t=34 is 0.4789320040944097\n",
      "Objective value at t=35 is 0.4789023866017533\n",
      "Objective value at t=36 is 0.4788768110659546\n",
      "Objective value at t=37 is 0.47885470836756794\n",
      "Objective value at t=38 is 0.47883559278103144\n",
      "Objective value at t=39 is 0.47881904912769807\n",
      "Objective value at t=40 is 0.4788047220319335\n",
      "Objective value at t=41 is 0.47879230691094676\n",
      "Objective value at t=42 is 0.47878154239904325\n",
      "Objective value at t=43 is 0.47877220396265513\n",
      "Objective value at t=44 is 0.4787640985069849\n",
      "Objective value at t=45 is 0.4787570598108185\n",
      "Objective value at t=46 is 0.47875094465488705\n",
      "Objective value at t=47 is 0.4787456295325166\n",
      "Objective value at t=48 is 0.4787410078503053\n",
      "Objective value at t=49 is 0.4787369875421076\n",
      "Objective value at t=50 is 0.4787334890323296\n",
      "Objective value at t=51 is 0.4787304434950227\n",
      "Objective value at t=52 is 0.4787277913639165\n",
      "Objective value at t=53 is 0.4787254810556898\n",
      "Objective value at t=54 is 0.47872346787473546\n",
      "Objective value at t=55 is 0.47872171307262734\n",
      "Objective value at t=56 is 0.47872018303963904\n",
      "Objective value at t=57 is 0.47871884860912506\n",
      "Objective value at t=58 is 0.4787176844584852\n",
      "Objective value at t=59 is 0.4787166685928756\n",
      "Objective value at t=60 is 0.4787157818998882\n",
      "Objective value at t=61 is 0.4787150077651638\n",
      "Objective value at t=62 is 0.4787143317403636\n",
      "Objective value at t=63 is 0.478713741256187\n",
      "Objective value at t=64 is 0.4787132253741612\n",
      "Objective value at t=65 is 0.47871277457184314\n",
      "Objective value at t=66 is 0.47871238055682785\n",
      "Objective value at t=67 is 0.47871203610561663\n",
      "Objective value at t=68 is 0.4787117349239492\n",
      "Objective value at t=69 is 0.4787114715256837\n",
      "Objective value at t=70 is 0.4787112411277113\n",
      "Objective value at t=71 is 0.4787110395587439\n",
      "Objective value at t=72 is 0.47871086318010897\n",
      "Objective value at t=73 is 0.478710708816944\n",
      "Objective value at t=74 is 0.4787105736984016\n",
      "Objective value at t=75 is 0.4787104554056655\n",
      "Objective value at t=76 is 0.478710351826742\n",
      "Objective value at t=77 is 0.4787102611171305\n",
      "Objective value at t=78 is 0.4787101816655955\n",
      "Objective value at t=79 is 0.47871011206437103\n",
      "Objective value at t=80 is 0.4787100510832145\n",
      "Objective value at t=81 is 0.47870999764680644\n",
      "Objective value at t=82 is 0.4787099508150588\n",
      "Objective value at t=83 is 0.478709909765952\n",
      "Objective value at t=84 is 0.4787098737805743\n",
      "Objective value at t=85 is 0.4787098422300757\n",
      "Objective value at t=86 is 0.4787098145642873\n",
      "Objective value at t=87 is 0.478709790301795\n",
      "Objective value at t=88 is 0.4787097690212763\n",
      "Objective value at t=89 is 0.478709750353938\n",
      "Objective value at t=90 is 0.47870973397691596\n",
      "Objective value at t=91 is 0.4787097196075097\n",
      "Objective value at t=92 is 0.4787097069981489\n",
      "Objective value at t=93 is 0.4787096959319945\n",
      "Objective value at t=94 is 0.4787096862190959\n",
      "Objective value at t=95 is 0.4787096776930326\n",
      "Objective value at t=96 is 0.47870967020797917\n",
      "Objective value at t=97 is 0.4787096636361381\n",
      "Objective value at t=98 is 0.478709657865496\n",
      "Objective value at t=99 is 0.4787096527978611\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 1.0\n",
    "w, objvals_gd = grad_descent(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Stochastic gradient descent (SGD)\n",
    "\n",
    "Define $Q_i (w) = \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $.\n",
    "\n",
    "The stochastic gradient at $w$ is $g_i = \\frac{\\partial Q_i }{ \\partial w} = -\\frac{y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_i and the gradient of Q_i\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: 1-by-d matrix\n",
    "#     yi: scalar\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def stochastic_objective_gradient(w, xi, yi, lam):\n",
    "    d = xi.shape[0]\n",
    "    yx = yi * xi # 1-by-d matrix\n",
    "    yxw = float(numpy.dot(yx, w)) # scalar\n",
    "    \n",
    "    # calculate objective function Q_i\n",
    "    loss = numpy.log(1 + numpy.exp(-yxw)) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    obj = loss + reg\n",
    "    \n",
    "    # calculate stochastic gradient\n",
    "    g_loss = -yx.T / (1 + numpy.exp(yxw)) # d-by-1 matrix\n",
    "    g = g_loss + lam * w # d-by-1 matrix\n",
    "    \n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "def sgd(x, y, lam, stepsize, max_epoch=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_epoch) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_epoch):\n",
    "        # randomly shuffle the samples\n",
    "        rand_indices = numpy.random.permutation(n)\n",
    "        x_rand = x[rand_indices, :]\n",
    "        y_rand = y[rand_indices, :]\n",
    "        \n",
    "        objval = 0 # accumulate the objective values\n",
    "        for i in range(n):\n",
    "            xi = x_rand[i, :] # 1-by-d matrix\n",
    "            yi = float(y_rand[i, :]) # scalar\n",
    "            obj, g = stochastic_objective_gradient(w, xi, yi, lam)\n",
    "            objval += obj\n",
    "            w -= stepsize * g\n",
    "        \n",
    "        stepsize *= 0.9 # decrease step size\n",
    "        objval /= n\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at epoch t=' + str(t) + ' is ' + str(objval))\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at epoch t=0 is 0.5379035564228872\n",
      "Objective value at epoch t=1 is 0.5253452236820628\n",
      "Objective value at epoch t=2 is 0.5230535284263912\n",
      "Objective value at epoch t=3 is 0.5160741417612058\n",
      "Objective value at epoch t=4 is 0.519527413329417\n",
      "Objective value at epoch t=5 is 0.5086836264933087\n",
      "Objective value at epoch t=6 is 0.5089259502069197\n",
      "Objective value at epoch t=7 is 0.5029421138640336\n",
      "Objective value at epoch t=8 is 0.5048224208551085\n",
      "Objective value at epoch t=9 is 0.5045158354320879\n",
      "Objective value at epoch t=10 is 0.4958262785760975\n",
      "Objective value at epoch t=11 is 0.49998337717083274\n",
      "Objective value at epoch t=12 is 0.49576815560483684\n",
      "Objective value at epoch t=13 is 0.4953760237033037\n",
      "Objective value at epoch t=14 is 0.493364897521992\n",
      "Objective value at epoch t=15 is 0.4893657106170344\n",
      "Objective value at epoch t=16 is 0.4897196788347916\n",
      "Objective value at epoch t=17 is 0.4888758722566425\n",
      "Objective value at epoch t=18 is 0.4883573545802027\n",
      "Objective value at epoch t=19 is 0.4871227817982791\n",
      "Objective value at epoch t=20 is 0.486501026250282\n",
      "Objective value at epoch t=21 is 0.48615067846374815\n",
      "Objective value at epoch t=22 is 0.48501546730549566\n",
      "Objective value at epoch t=23 is 0.48507601321636395\n",
      "Objective value at epoch t=24 is 0.4840317098726571\n",
      "Objective value at epoch t=25 is 0.4836462874639558\n",
      "Objective value at epoch t=26 is 0.4829446799907277\n",
      "Objective value at epoch t=27 is 0.48278354157775516\n",
      "Objective value at epoch t=28 is 0.48230687426099106\n",
      "Objective value at epoch t=29 is 0.4819943107661732\n",
      "Objective value at epoch t=30 is 0.4818282525049805\n",
      "Objective value at epoch t=31 is 0.4814482852213196\n",
      "Objective value at epoch t=32 is 0.4811282659264774\n",
      "Objective value at epoch t=33 is 0.48087896707135414\n",
      "Objective value at epoch t=34 is 0.4806845740991692\n",
      "Objective value at epoch t=35 is 0.4805670636916465\n",
      "Objective value at epoch t=36 is 0.48029605408853415\n",
      "Objective value at epoch t=37 is 0.4801776075161186\n",
      "Objective value at epoch t=38 is 0.4800480901029981\n",
      "Objective value at epoch t=39 is 0.4799276104963397\n",
      "Objective value at epoch t=40 is 0.47979161326506875\n",
      "Objective value at epoch t=41 is 0.479685141094652\n",
      "Objective value at epoch t=42 is 0.479600610955901\n",
      "Objective value at epoch t=43 is 0.47951331703662553\n",
      "Objective value at epoch t=44 is 0.4794352986858558\n",
      "Objective value at epoch t=45 is 0.4793634820806297\n",
      "Objective value at epoch t=46 is 0.47929593303502094\n",
      "Objective value at epoch t=47 is 0.47923642815264883\n",
      "Objective value at epoch t=48 is 0.4791838625327681\n",
      "Objective value at epoch t=49 is 0.47913507471589734\n",
      "Objective value at epoch t=50 is 0.47909655676531526\n",
      "Objective value at epoch t=51 is 0.4790549183407826\n",
      "Objective value at epoch t=52 is 0.4790224304718308\n",
      "Objective value at epoch t=53 is 0.47898986512391756\n",
      "Objective value at epoch t=54 is 0.47896290614543063\n",
      "Objective value at epoch t=55 is 0.47893870219789314\n",
      "Objective value at epoch t=56 is 0.4789159165453927\n",
      "Objective value at epoch t=57 is 0.478894619056737\n",
      "Objective value at epoch t=58 is 0.4788767246016457\n",
      "Objective value at epoch t=59 is 0.478860444840158\n",
      "Objective value at epoch t=60 is 0.4788453123365005\n",
      "Objective value at epoch t=61 is 0.4788317849766893\n",
      "Objective value at epoch t=62 is 0.47881958519411116\n",
      "Objective value at epoch t=63 is 0.47880874582586275\n",
      "Objective value at epoch t=64 is 0.4787988589431267\n",
      "Objective value at epoch t=65 is 0.47878986174535854\n",
      "Objective value at epoch t=66 is 0.4787818414219389\n",
      "Objective value at epoch t=67 is 0.4787747835520749\n",
      "Objective value at epoch t=68 is 0.47876824199491336\n",
      "Objective value at epoch t=69 is 0.4787624425603922\n",
      "Objective value at epoch t=70 is 0.4787572298189452\n",
      "Objective value at epoch t=71 is 0.4787524860000292\n",
      "Objective value at epoch t=72 is 0.4787482400032451\n",
      "Objective value at epoch t=73 is 0.47874438006009834\n",
      "Objective value at epoch t=74 is 0.47874094011186286\n",
      "Objective value at epoch t=75 is 0.4787378483959627\n",
      "Objective value at epoch t=76 is 0.478735052862765\n",
      "Objective value at epoch t=77 is 0.47873251345373485\n",
      "Objective value at epoch t=78 is 0.4787302757130125\n",
      "Objective value at epoch t=79 is 0.47872823454419955\n",
      "Objective value at epoch t=80 is 0.4787264068448859\n",
      "Objective value at epoch t=81 is 0.47872474931525766\n",
      "Objective value at epoch t=82 is 0.4787232658367796\n",
      "Objective value at epoch t=83 is 0.4787219346955299\n",
      "Objective value at epoch t=84 is 0.4787207309926552\n",
      "Objective value at epoch t=85 is 0.4787196445539329\n",
      "Objective value at epoch t=86 is 0.4787186722599894\n",
      "Objective value at epoch t=87 is 0.47871779646381774\n",
      "Objective value at epoch t=88 is 0.4787170066302463\n",
      "Objective value at epoch t=89 is 0.4787162959370983\n",
      "Objective value at epoch t=90 is 0.47871565695881513\n",
      "Objective value at epoch t=91 is 0.478715080977649\n",
      "Objective value at epoch t=92 is 0.4787145630222224\n",
      "Objective value at epoch t=93 is 0.47871409689977096\n",
      "Objective value at epoch t=94 is 0.47871367721717484\n",
      "Objective value at epoch t=95 is 0.4787132995720663\n",
      "Objective value at epoch t=96 is 0.4787129595319738\n",
      "Objective value at epoch t=97 is 0.4787126537523312\n",
      "Objective value at epoch t=98 is 0.4787123783853137\n",
      "Objective value at epoch t=99 is 0.4787121304327594\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 0.1\n",
    "w, objvals_sgd = sgd(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare GD with SGD\n",
    "\n",
    "Plot objective function values against epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "\n",
    "epochs_gd = range(len(objvals_gd))\n",
    "epochs_sgd = range(len(objvals_sgd))\n",
    "\n",
    "line0, = plt.plot(epochs_gd, objvals_gd, '--b', LineWidth=4)\n",
    "line1, = plt.plot(epochs_sgd, objvals_sgd, '-r', LineWidth=2)\n",
    "plt.xlabel('Epochs', FontSize=20)\n",
    "plt.ylabel('Objective Value', FontSize=20)\n",
    "plt.xticks(FontSize=16)\n",
    "plt.yticks(FontSize=16)\n",
    "plt.legend([line0, line1], ['GD', 'SGD'], fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('compare_gd_sgd.pdf', format='pdf', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class label\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     X: m-by-d matrix\n",
    "# Return:\n",
    "#     f: m-by-1 matrix, the predictions\n",
    "def predict(w, X):\n",
    "    xw = numpy.dot(X, w)\n",
    "    f = numpy.sign(xw)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error is 0.2265625\n"
     ]
    }
   ],
   "source": [
    "# evaluate training error\n",
    "f_train = predict(w, x_train)\n",
    "diff = numpy.abs(f_train - y_train) / 2\n",
    "error_train = numpy.mean(diff)\n",
    "print('Training classification error is ' + str(error_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test classification error is 0.203125\n"
     ]
    }
   ],
   "source": [
    "# evaluate test error\n",
    "f_test = predict(w, x_test)\n",
    "diff = numpy.abs(f_test - y_test) / 2\n",
    "error_test = numpy.mean(diff)\n",
    "print('Test classification error is ' + str(error_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Mini-batch SGD (fill the code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Compute the objective $Q_I$ and its gradient using a batch of samples\n",
    "\n",
    "Define $Q_I (w) = \\frac{1}{b} \\sum_{i \\in I} \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $, where $I$ is a set containing $b$ indices randomly drawn from $\\{ 1, \\cdots , n \\}$ without replacement.\n",
    "\n",
    "The stochastic gradient at $w$ is $g_I = \\frac{\\partial Q_I }{ \\partial w} = \\frac{1}{b} \\sum_{i \\in I} \\frac{- y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_I and the gradient of Q_I\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: b-by-d matrix\n",
    "#     yi: b-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     b: integer, the batch size\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def mb_stochastic_objective_gradient(w, xi, yi, lam, b):\n",
    "    b, d = xi.shape\n",
    "    yx = numpy.multiply(yi,xi) # b by d matrix\n",
    "    yxw = numpy.dot(yx,w) # b by 1 vector\n",
    "    vec1 = numpy.exp(-1 * yxw) \n",
    "    vec2 = numpy.log(1+vec1) \n",
    "    loss = numpy.mean(vec2)\n",
    "    reg = lam / 2 * numpy.sum(w * w)\n",
    "    obj = loss + reg\n",
    "    \n",
    "    g_vec = -yx / (1 + numpy.exp(yxw))\n",
    "    g = numpy.mean(g_vec,axis=0).reshape(d,1)\n",
    "    g += lam * w\n",
    "    \n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Implement mini-batch SGD\n",
    "\n",
    "Hints:\n",
    "1. In every epoch, randomly permute the $n$ samples (just like SGD).\n",
    "2. Each epoch has $\\frac{n}{b}$ iterations. In every iteration, use $b$ samples, and compute the gradient and objective using the ``mb_stochastic_objective_gradient`` function. In the next iteration, use the next $b$ samples, and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-Batch SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     b: integer, the batch size\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "def mb_sgd(x, y, lam, b, stepsize, max_epoch=100, w=None):\n",
    "    # Fill the function\n",
    "    # Follow the implementation of sgd\n",
    "    # Record one objective value per epoch (not per iteration!)\n",
    "    n,d = x.shape\n",
    "    objvals = []\n",
    "    \n",
    "    chunks = n // b\n",
    "    # in the case of bad chunk size\n",
    "    if n % b != 0:\n",
    "        chunks += 1\n",
    "    \n",
    "    # intialization to 0\n",
    "    if w == None:\n",
    "        w = numpy.zeros((d,1))\n",
    "    # iterate through max_epochs\n",
    "    for t in range(max_epoch):\n",
    "        # randomly shuffle the training data and labels\n",
    "        epoch_obj = 0\n",
    "        rand_indices = numpy.random.permutation(n)\n",
    "        x_rand = x[rand_indices, :]\n",
    "        y_rand = y[rand_indices, :]\n",
    "        # divide into minibatches and get the gradient and objval\n",
    "        for i in range(chunks):\n",
    "            # start and stop for the batch\n",
    "            start = i * b\n",
    "            end = (i+1) * b\n",
    "            # acquire a minibatch\n",
    "            xi = x_rand[start:end,:]\n",
    "            yi = y_rand[start:end,:]\n",
    "            \n",
    "            obj, gradient = mb_stochastic_objective_gradient(w,xi,yi,lam,b)\n",
    "            \n",
    "            #update obj_val and gradient\n",
    "            epoch_obj += obj\n",
    "            w -= stepsize * gradient\n",
    "        stepsize *= .9\n",
    "        epoch_obj /= chunks\n",
    "        objvals.append(epoch_obj)\n",
    "        print('Objective value at epoch t=' + str(t) + ' is ' + str(epoch_obj))\n",
    "        \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Run MB-SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at epoch t=0 is 0.5243320189211326\n",
      "Objective value at epoch t=1 is 0.5045725093846494\n",
      "Objective value at epoch t=2 is 0.5034218193025439\n",
      "Objective value at epoch t=3 is 0.4967404242753262\n",
      "Objective value at epoch t=4 is 0.4982801460144871\n",
      "Objective value at epoch t=5 is 0.4950394004547973\n",
      "Objective value at epoch t=6 is 0.4954942989459285\n",
      "Objective value at epoch t=7 is 0.49395114412328817\n",
      "Objective value at epoch t=8 is 0.4918962824939275\n",
      "Objective value at epoch t=9 is 0.4903761875581917\n",
      "Objective value at epoch t=10 is 0.4880542129008809\n",
      "Objective value at epoch t=11 is 0.48981006040256964\n",
      "Objective value at epoch t=12 is 0.4880215832339987\n",
      "Objective value at epoch t=13 is 0.4867521298997361\n",
      "Objective value at epoch t=14 is 0.48600913451271827\n",
      "Objective value at epoch t=15 is 0.4862098869708795\n",
      "Objective value at epoch t=16 is 0.48451845183688036\n",
      "Objective value at epoch t=17 is 0.484150693641901\n",
      "Objective value at epoch t=18 is 0.4838399382172741\n",
      "Objective value at epoch t=19 is 0.4828739401825584\n",
      "Objective value at epoch t=20 is 0.4833670663889163\n",
      "Objective value at epoch t=21 is 0.4824437834472387\n",
      "Objective value at epoch t=22 is 0.48204026920554277\n",
      "Objective value at epoch t=23 is 0.48162931573117695\n",
      "Objective value at epoch t=24 is 0.4812865557593864\n",
      "Objective value at epoch t=25 is 0.4812356896811109\n",
      "Objective value at epoch t=26 is 0.48129819379778455\n",
      "Objective value at epoch t=27 is 0.4808373624267824\n",
      "Objective value at epoch t=28 is 0.48069670269535847\n",
      "Objective value at epoch t=29 is 0.48057933988921525\n",
      "Objective value at epoch t=30 is 0.480227431643889\n",
      "Objective value at epoch t=31 is 0.4800562633065687\n",
      "Objective value at epoch t=32 is 0.4800167481497626\n",
      "Objective value at epoch t=33 is 0.4798467707137323\n",
      "Objective value at epoch t=34 is 0.47966055457736656\n",
      "Objective value at epoch t=35 is 0.4796325560020481\n",
      "Objective value at epoch t=36 is 0.4795008785066326\n",
      "Objective value at epoch t=37 is 0.4794948524895891\n",
      "Objective value at epoch t=38 is 0.4793600594751096\n",
      "Objective value at epoch t=39 is 0.4793247746938847\n",
      "Objective value at epoch t=40 is 0.4792978760176491\n",
      "Objective value at epoch t=41 is 0.47923937363505137\n",
      "Objective value at epoch t=42 is 0.4791445724072734\n",
      "Objective value at epoch t=43 is 0.4790893169101659\n",
      "Objective value at epoch t=44 is 0.4790339369562835\n",
      "Objective value at epoch t=45 is 0.4790239179121471\n",
      "Objective value at epoch t=46 is 0.4789819219613901\n",
      "Objective value at epoch t=47 is 0.47897609460430945\n",
      "Objective value at epoch t=48 is 0.4789266671988452\n",
      "Objective value at epoch t=49 is 0.478923881840037\n",
      "Objective value at epoch t=50 is 0.47890292238623094\n",
      "Objective value at epoch t=51 is 0.4788759556970602\n",
      "Objective value at epoch t=52 is 0.478859506199537\n",
      "Objective value at epoch t=53 is 0.4788561492850668\n",
      "Objective value at epoch t=54 is 0.4788324976738485\n",
      "Objective value at epoch t=55 is 0.47882225266584416\n",
      "Objective value at epoch t=56 is 0.47880542024593026\n",
      "Objective value at epoch t=57 is 0.4788034958617933\n",
      "Objective value at epoch t=58 is 0.47878736756943924\n",
      "Objective value at epoch t=59 is 0.4787805631952976\n",
      "Objective value at epoch t=60 is 0.47878013093148547\n",
      "Objective value at epoch t=61 is 0.47876569328686625\n",
      "Objective value at epoch t=62 is 0.47876753579212056\n",
      "Objective value at epoch t=63 is 0.4787605361434961\n",
      "Objective value at epoch t=64 is 0.4787545708384691\n",
      "Objective value at epoch t=65 is 0.4787530033485316\n",
      "Objective value at epoch t=66 is 0.47874416946262766\n",
      "Objective value at epoch t=67 is 0.47874358246489246\n",
      "Objective value at epoch t=68 is 0.47873840980609483\n",
      "Objective value at epoch t=69 is 0.47873633363114837\n",
      "Objective value at epoch t=70 is 0.4787334873757845\n",
      "Objective value at epoch t=71 is 0.4787319993603608\n",
      "Objective value at epoch t=72 is 0.47872810913681346\n",
      "Objective value at epoch t=73 is 0.4787263100992658\n",
      "Objective value at epoch t=74 is 0.4787248073457094\n",
      "Objective value at epoch t=75 is 0.4787231214341852\n",
      "Objective value at epoch t=76 is 0.47872400099303\n",
      "Objective value at epoch t=77 is 0.47872043734992314\n",
      "Objective value at epoch t=78 is 0.4787202029244585\n",
      "Objective value at epoch t=79 is 0.47871821710292817\n",
      "Objective value at epoch t=80 is 0.478718083412489\n",
      "Objective value at epoch t=81 is 0.47871821858714486\n",
      "Objective value at epoch t=82 is 0.4787165067071652\n",
      "Objective value at epoch t=83 is 0.47871554347773165\n",
      "Objective value at epoch t=84 is 0.4787150814518978\n",
      "Objective value at epoch t=85 is 0.4787145140569993\n",
      "Objective value at epoch t=86 is 0.4787139388653796\n",
      "Objective value at epoch t=87 is 0.47871372145958474\n",
      "Objective value at epoch t=88 is 0.4787136889297837\n",
      "Objective value at epoch t=89 is 0.4787126272108548\n",
      "Objective value at epoch t=90 is 0.478712880138219\n",
      "Objective value at epoch t=91 is 0.47871229133008775\n",
      "Objective value at epoch t=92 is 0.47871209045808527\n",
      "Objective value at epoch t=93 is 0.4787119602609919\n",
      "Objective value at epoch t=94 is 0.47871174014762846\n",
      "Objective value at epoch t=95 is 0.47871139893437614\n",
      "Objective value at epoch t=96 is 0.4787112376263294\n",
      "Objective value at epoch t=97 is 0.47871120869889083\n",
      "Objective value at epoch t=98 is 0.478711121239441\n",
      "Objective value at epoch t=99 is 0.4787109336281639\n"
     ]
    }
   ],
   "source": [
    "# MB-SGD with batch size b=8\n",
    "lam = 1E-6 # do not change\n",
    "b = 8 # do not change\n",
    "stepsize = 0.4 # you must tune this parameter\n",
    "\n",
    "w, objvals_mbsgd8 = mb_sgd(x_train, y_train, lam, b, stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at epoch t=0 is 0.5523330873969348\n",
      "Objective value at epoch t=1 is 0.4908958898469806\n",
      "Objective value at epoch t=2 is 0.48773560371876246\n",
      "Objective value at epoch t=3 is 0.4863838456170958\n",
      "Objective value at epoch t=4 is 0.487462852384957\n",
      "Objective value at epoch t=5 is 0.48439298970883804\n",
      "Objective value at epoch t=6 is 0.48376862598411396\n",
      "Objective value at epoch t=7 is 0.48292381129972295\n",
      "Objective value at epoch t=8 is 0.48298995193716204\n",
      "Objective value at epoch t=9 is 0.4814678092815442\n",
      "Objective value at epoch t=10 is 0.48203949747143754\n",
      "Objective value at epoch t=11 is 0.48142321939396265\n",
      "Objective value at epoch t=12 is 0.48210232944437326\n",
      "Objective value at epoch t=13 is 0.48126771585133205\n",
      "Objective value at epoch t=14 is 0.4809166090220092\n",
      "Objective value at epoch t=15 is 0.4808192055610526\n",
      "Objective value at epoch t=16 is 0.4808271159134181\n",
      "Objective value at epoch t=17 is 0.4804317023182184\n",
      "Objective value at epoch t=18 is 0.48012256868866876\n",
      "Objective value at epoch t=19 is 0.4800302199701128\n",
      "Objective value at epoch t=20 is 0.4795280120784682\n",
      "Objective value at epoch t=21 is 0.4799415984898193\n",
      "Objective value at epoch t=22 is 0.4793593918643924\n",
      "Objective value at epoch t=23 is 0.47991924979443823\n",
      "Objective value at epoch t=24 is 0.4795479891545047\n",
      "Objective value at epoch t=25 is 0.47926678306567727\n",
      "Objective value at epoch t=26 is 0.47949704209488064\n",
      "Objective value at epoch t=27 is 0.479310094680988\n",
      "Objective value at epoch t=28 is 0.479279168742529\n",
      "Objective value at epoch t=29 is 0.47924214393380027\n",
      "Objective value at epoch t=30 is 0.4791301050039206\n",
      "Objective value at epoch t=31 is 0.47905788332380544\n",
      "Objective value at epoch t=32 is 0.47897203367974645\n",
      "Objective value at epoch t=33 is 0.4791010551530965\n",
      "Objective value at epoch t=34 is 0.47898178675845393\n",
      "Objective value at epoch t=35 is 0.47892711446103364\n",
      "Objective value at epoch t=36 is 0.47891001845502146\n",
      "Objective value at epoch t=37 is 0.47886760744075074\n",
      "Objective value at epoch t=38 is 0.4789066658022456\n",
      "Objective value at epoch t=39 is 0.4788803181245867\n",
      "Objective value at epoch t=40 is 0.4788336268602749\n",
      "Objective value at epoch t=41 is 0.4788507397555685\n",
      "Objective value at epoch t=42 is 0.47880451388887507\n",
      "Objective value at epoch t=43 is 0.4788401075311303\n",
      "Objective value at epoch t=44 is 0.4788145068651207\n",
      "Objective value at epoch t=45 is 0.47879033432162477\n",
      "Objective value at epoch t=46 is 0.47878324422583185\n",
      "Objective value at epoch t=47 is 0.47878176375790343\n",
      "Objective value at epoch t=48 is 0.47876298088699665\n",
      "Objective value at epoch t=49 is 0.47876861651535335\n",
      "Objective value at epoch t=50 is 0.4787717012533611\n",
      "Objective value at epoch t=51 is 0.47875618399984426\n",
      "Objective value at epoch t=52 is 0.4787482607488567\n",
      "Objective value at epoch t=53 is 0.4787514471680547\n",
      "Objective value at epoch t=54 is 0.47874656492571493\n",
      "Objective value at epoch t=55 is 0.47874672551531106\n",
      "Objective value at epoch t=56 is 0.4787329363447005\n",
      "Objective value at epoch t=57 is 0.47873908312332364\n",
      "Objective value at epoch t=58 is 0.47873031054474496\n",
      "Objective value at epoch t=59 is 0.47872783148577625\n",
      "Objective value at epoch t=60 is 0.4787259558963345\n",
      "Objective value at epoch t=61 is 0.4787279236824459\n",
      "Objective value at epoch t=62 is 0.47872646970685134\n",
      "Objective value at epoch t=63 is 0.47872460284480944\n",
      "Objective value at epoch t=64 is 0.4787233648492107\n",
      "Objective value at epoch t=65 is 0.4787182930459343\n",
      "Objective value at epoch t=66 is 0.4787196618668287\n",
      "Objective value at epoch t=67 is 0.4787189021885019\n",
      "Objective value at epoch t=68 is 0.47871766143358896\n",
      "Objective value at epoch t=69 is 0.4787166251490859\n",
      "Objective value at epoch t=70 is 0.4787158573503638\n",
      "Objective value at epoch t=71 is 0.47871617895917334\n",
      "Objective value at epoch t=72 is 0.47871426990325416\n",
      "Objective value at epoch t=73 is 0.478713876523179\n",
      "Objective value at epoch t=74 is 0.4787148684060667\n",
      "Objective value at epoch t=75 is 0.47871392178593286\n",
      "Objective value at epoch t=76 is 0.47871337804834163\n",
      "Objective value at epoch t=77 is 0.4787133899894155\n",
      "Objective value at epoch t=78 is 0.47871373339237666\n",
      "Objective value at epoch t=79 is 0.4787120299126203\n",
      "Objective value at epoch t=80 is 0.47871204828771263\n",
      "Objective value at epoch t=81 is 0.4787114781349846\n",
      "Objective value at epoch t=82 is 0.47871158631052513\n",
      "Objective value at epoch t=83 is 0.47871127176543754\n",
      "Objective value at epoch t=84 is 0.4787110792524638\n",
      "Objective value at epoch t=85 is 0.47871100947454115\n",
      "Objective value at epoch t=86 is 0.47871098083918584\n",
      "Objective value at epoch t=87 is 0.4787111730885515\n",
      "Objective value at epoch t=88 is 0.4787108494334148\n",
      "Objective value at epoch t=89 is 0.47871086556655185\n",
      "Objective value at epoch t=90 is 0.47871074634940863\n",
      "Objective value at epoch t=91 is 0.4787104034508373\n",
      "Objective value at epoch t=92 is 0.47871039769864343\n",
      "Objective value at epoch t=93 is 0.47871041748430854\n",
      "Objective value at epoch t=94 is 0.4787104276181989\n",
      "Objective value at epoch t=95 is 0.47871032085355913\n",
      "Objective value at epoch t=96 is 0.47871022481736514\n",
      "Objective value at epoch t=97 is 0.47871026508314707\n",
      "Objective value at epoch t=98 is 0.47871014651588856\n",
      "Objective value at epoch t=99 is 0.47871020430962546\n"
     ]
    }
   ],
   "source": [
    "# MB-SGD with batch size b=64\n",
    "lam = 1E-6 # do not change\n",
    "b = 64 # do not change\n",
    "stepsize = 1.0 # you must tune this parameter\n",
    "\n",
    "w, objvals_mbsgd64 = mb_sgd(x_train, y_train, lam, b, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Plot and compare GD, SGD, and MB-SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to compare the following algorithms:\n",
    "\n",
    "- Gradient descent (GD)\n",
    "\n",
    "- SGD\n",
    "\n",
    "- MB-SGD with b=8\n",
    "\n",
    "- MB-SGD with b=64\n",
    "\n",
    "Follow the code in Section 4 to plot ```objective function value``` against ```epochs```. There should be four curves in the plot; each curve corresponds to one algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Logistic regression with $\\ell_2$-norm regularization is a strongly convex optimization problem. All the algorithms will converge to the same solution. **In the end, the ``objective function value`` of the 4 algorithms will be the same. If not the same, your implementation must be wrong. Do NOT submit wrong code and wrong result!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 4 curves:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
