{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus1.1: Federated Averaging\n",
    "\n",
    "### Name: Vincent Lee\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read the lecture note: [click here](https://github.com/wangshusen/DeepLearning/blob/master/LectureNotes/Parallel/Parallel.pdf)\n",
    "\n",
    "2. Implement **federated averaging** or decentralized optimization.\n",
    "\n",
    "3. Plot the convergence curve. (The x-axis can be ```number of epochs``` or ```number of communication```. You must make sure the label is correct.)\n",
    "\n",
    "4. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain **the code** and **the output after execution**.\n",
    "    \n",
    "5. Upload this .HTML file to your Google Drive, Dropbox, or your Github repo. (If it is submitted to Google Drive or Dropbox, you must make the file open-access.)\n",
    "\n",
    "6. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/Bonus1/Bonus1.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data processing\n",
    "\n",
    "- Download the Diabete dataset from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes\n",
    "- Load the data using sklearn.\n",
    "- Preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (768, 8)\n",
      "Shape of y: (768,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy\n",
    "\n",
    "x_sparse, y = datasets.load_svmlight_file('diabetes')\n",
    "x = x_sparse.todense()\n",
    "\n",
    "print('Shape of x: ' + str(x.shape))\n",
    "print('Shape of y: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Partition to training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 8)\n",
      "Shape of x_test: (128, 8)\n",
      "Shape of y_train: (640, 1)\n",
      "Shape of y_test: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "# partition the data to training and test sets\n",
    "n = x.shape[0]\n",
    "n_train = 640\n",
    "n_test = n - n_train\n",
    "\n",
    "rand_indices = numpy.random.permutation(n)\n",
    "train_indices = rand_indices[0:n_train]\n",
    "test_indices = rand_indices[n_train:n]\n",
    "\n",
    "x_train = x[train_indices, :]\n",
    "x_test = x[test_indices, :]\n",
    "y_train = y[train_indices].reshape(n_train, 1)\n",
    "y_test = y[test_indices].reshape(n_test, 1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the standardization to trainsform both training and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean = \n",
      "[[ 0.08893865  0.00625612 -0.06925102  0.00367375 -0.11008717 -0.0751612\n",
      "  -0.03220125 -0.1473439 ]]\n",
      "test std = \n",
      "[[1.01775645 0.94924062 1.13605568 0.91523984 0.73376482 0.87115693\n",
      "  1.04727104 0.91999902]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "import numpy\n",
    "\n",
    "# calculate mu and sig using the training set\n",
    "d = x_train.shape[1]\n",
    "mu = numpy.mean(x_train, axis=0).reshape(1, d)\n",
    "sig = numpy.std(x_train, axis=0).reshape(1, d)\n",
    "\n",
    "# transform the training features\n",
    "x_train = (x_train - mu) / (sig + 1E-6)\n",
    "\n",
    "# transform the test features\n",
    "x_test = (x_test - mu) / (sig + 1E-6)\n",
    "\n",
    "print('test mean = ')\n",
    "print(numpy.mean(x_test, axis=0))\n",
    "\n",
    "print('test std = ')\n",
    "print(numpy.std(x_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Add a dimension of all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 9)\n",
      "Shape of x_test: (128, 9)\n"
     ]
    }
   ],
   "source": [
    "n_train, d = x_train.shape\n",
    "x_train = numpy.concatenate((x_train, numpy.ones((n_train, 1))), axis=1)\n",
    "\n",
    "n_test, d = x_test.shape\n",
    "x_test = numpy.concatenate((x_test, numpy.ones((n_test, 1))), axis=1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Minibatch Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_I and the gradient of Q_I\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: b-by-d matrix\n",
    "#     yi: b-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     b: integer, the batch size\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def mb_stochastic_objective_gradient(w, xi, yi, lam, b):\n",
    "    b, d = xi.shape\n",
    "    yx = numpy.multiply(yi,xi) # b by d matrix\n",
    "    yxw = numpy.dot(yx,w) # b by 1 vector\n",
    "    vec1 = numpy.exp(-1 * yxw) \n",
    "    vec2 = numpy.log(1+vec1) \n",
    "    loss = numpy.mean(vec2)\n",
    "    reg = lam / 2 * numpy.sum(numpy.multiply(w,w))\n",
    "    obj = loss + reg\n",
    "    \n",
    "    g_vec = -yx / (1 + numpy.exp(yxw))\n",
    "    g = numpy.mean(g_vec,axis=0).reshape(d,1)\n",
    "    g += lam * w\n",
    "    \n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-20 14:55:11,953\tWARNING services.py:586 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-03-20 14:55:11,954\tINFO resource_spec.py:212 -- Starting Ray with 8.74 GiB memory available for workers and up to 4.39 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-03-20 14:55:12,240\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()\n",
    "\n",
    "@ray.remote\n",
    "class Server:\n",
    "    def __init__(self,m,d, stepsize):\n",
    "        self.m = m # number of workers\n",
    "        self.d = d # number of parameters \n",
    "        self.weight = numpy.zeros((d,1))\n",
    "        self.stepsize = stepsize\n",
    "        self.objvals = []\n",
    "        \n",
    "    def broadcast(self):\n",
    "        return self.weight,self.stepsize\n",
    "    \n",
    "    def aggregate(self,objvals,weights):\n",
    "        crnt_obj = 0 \n",
    "        crnt_gradient = numpy.zeros((self.d,1))\n",
    "        for i in range(self.m):\n",
    "            crnt_gradient += weights[i]\n",
    "            crnt_obj += objvals[i]\n",
    "        crnt_gradient /= self.m\n",
    "        crnt_obj /= self.m\n",
    "        self.weight = crnt_gradient\n",
    "        self.objvals.append(crnt_obj)\n",
    "        self.stepsize *= .9 \n",
    "    \n",
    "    def get_objvals(self):\n",
    "        return self.objvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Worker:\n",
    "    def __init__(self,x,y,b):\n",
    "        self.n = x.shape[0]\n",
    "        self.d = x.shape[1]\n",
    "        rand_indices = numpy.random.permutation(self.n)\n",
    "        self.x = x[rand_indices,:]\n",
    "        self.y = y[rand_indices,:]\n",
    "        self.b = b\n",
    "        # how many batches per update\n",
    "        # do one quarter of the total batches\n",
    "        self.batches = self.n//b//4\n",
    "        # current batch\n",
    "        self.crnt_batch = 0\n",
    "        \n",
    "    def update_params(self,weight,stepsize):\n",
    "        self.weight = weight\n",
    "        if self.crnt_batch == self.batches * 4:\n",
    "            self.crnt_batch = 0\n",
    "            rand_indices = numpy.random.permutation(self.n)\n",
    "            self.x = self.x[rand_indices,:]\n",
    "            self.y = self.y[rand_indices,:]\n",
    "        crnt_obj = 0\n",
    "        for i in range(self.crnt_batch, self.crnt_batch + self.batches):\n",
    "            xi = self.x[i*self.b:(i+1)*self.b,:]\n",
    "            yi = self.y[i*self.b:(i+1)*self.b,:]\n",
    "            obj, w = mb_stochastic_objective_gradient(self.weight,xi,yi,stepsize,self.b)\n",
    "            self.weight = self.weight - stepsize * w\n",
    "            crnt_obj += obj\n",
    "        \n",
    "        crnt_obj /= self.batches\n",
    "        return crnt_obj, self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MB-SGD with batch size b=8\n",
    "lam = 1E-6 # do not change\n",
    "b = 8 # do not change\n",
    "stepsize = 0.4 # you must tune this parameter\n",
    "m = 5\n",
    "maxepochs =100\n",
    "d = x_train.shape[1]\n",
    "\n",
    "server = Server.remote(4,d,stepsize)\n",
    "workers = []\n",
    "chunksize = n_train // m\n",
    "for i in range(m):\n",
    "    x = x_train[i*chunksize:(i+1)*chunksize,:]\n",
    "    y = y_train[i*chunksize:(i+1)*chunksize,:]\n",
    "    workers.append(Worker.remote(x,y,b))\n",
    "\n",
    "    \n",
    "for i in range(maxepochs):\n",
    "    # since each worker update only does 1/4 of the data its given\n",
    "    # one epoch is 4 updates\n",
    "    for i in range(4):\n",
    "        objvals = []\n",
    "        weights = []\n",
    "        w, stepsize = ray.get(server.broadcast.remote())\n",
    "        for worker in workers:\n",
    "            obj, weight = ray.get(worker.update_params.remote(w,stepsize))\n",
    "            objvals.append(obj)\n",
    "            weights.append(weight)\n",
    "        server.aggregate.remote(objvals,weights)\n",
    "\n",
    "objvals = ray.get(server.get_objvals.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "communications = range(len(objvals))\n",
    "line0, = plt.plot(communications, objvals, LineWidth=4)\n",
    "plt.xlabel('Communications', FontSize=20)\n",
    "plt.ylabel('Objective Value', FontSize=20)\n",
    "plt.xticks(FontSize=16)\n",
    "plt.yticks(FontSize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
