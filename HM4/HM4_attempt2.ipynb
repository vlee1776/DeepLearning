{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 4: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Vincent Lee\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    samples = len(y)\n",
    "    ret = numpy.zeros((samples,num_class))\n",
    "    for i in range(samples):\n",
    "        ret[i,y[i]] = 1\n",
    "    return ret\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 32)   896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 16, 16, 32)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 32)   1056        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 16, 16, 32)   1056        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 16, 16, 32)   0           max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 16, 16, 32)   1056        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 32)   9248        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 16, 16, 32)   25632       conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 32)   1056        max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 128)  0           conv2d_81[0][0]                  \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "                                                                 conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 16, 16, 32)   4128        concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 16, 16, 32)   4128        concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 16, 16, 128)  0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 32)   4128        concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 16, 16, 32)   9248        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 16, 16, 32)   25632       conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 16, 16, 32)   4128        max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 128)  0           conv2d_87[0][0]                  \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "                                                                 conv2d_91[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 16, 16, 32)   4128        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 16, 16, 32)   4128        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 16, 16, 128)  0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 16, 16, 32)   4128        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 16, 16, 32)   9248        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 16, 16, 32)   25632       conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 16, 16, 32)   4128        max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 128)  0           conv2d_93[0][0]                  \n",
      "                                                                 conv2d_95[0][0]                  \n",
      "                                                                 conv2d_97[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 16, 16, 128)  0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 32)   4128        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 32)   9248        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 32)   25632       conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 32)   4128        max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 128)  0           conv2d_99[0][0]                  \n",
      "                                                                 conv2d_101[0][0]                 \n",
      "                                                                 conv2d_103[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 16, 16, 128)  0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 32)   9248        conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 32)   25632       conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 32)   4128        max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 128)  0           conv2d_105[0][0]                 \n",
      "                                                                 conv2d_107[0][0]                 \n",
      "                                                                 conv2d_109[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 16, 16, 128)  0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 32)   9248        conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 32)   25632       conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 32)   4128        max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 128)  0           conv2d_111[0][0]                 \n",
      "                                                                 conv2d_113[0][0]                 \n",
      "                                                                 conv2d_115[0][0]                 \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 16, 16, 128)  0           concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 32)   9248        conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 16, 16, 32)   25632       conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 32)   4128        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 128)  0           conv2d_117[0][0]                 \n",
      "                                                                 conv2d_119[0][0]                 \n",
      "                                                                 conv2d_121[0][0]                 \n",
      "                                                                 conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 16, 16, 128)  0           concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 16, 16, 32)   9248        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 16, 16, 32)   25632       conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 16, 16, 32)   4128        max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 128)  0           conv2d_123[0][0]                 \n",
      "                                                                 conv2d_125[0][0]                 \n",
      "                                                                 conv2d_127[0][0]                 \n",
      "                                                                 conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 16, 16, 128)  0           concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 16, 16, 32)   9248        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 16, 16, 32)   25632       conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 16, 16, 32)   4128        max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 128)  0           conv2d_129[0][0]                 \n",
      "                                                                 conv2d_131[0][0]                 \n",
      "                                                                 conv2d_133[0][0]                 \n",
      "                                                                 conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 16, 16, 128)  0           concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 16, 16, 32)   9248        conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 16, 16, 32)   25632       conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 16, 16, 32)   4128        max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 128)  0           conv2d_135[0][0]                 \n",
      "                                                                 conv2d_137[0][0]                 \n",
      "                                                                 conv2d_139[0][0]                 \n",
      "                                                                 conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 16, 16, 128)  0           concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 16, 16, 32)   9248        conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 16, 16, 32)   25632       conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 16, 16, 32)   4128        max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 128)  0           conv2d_141[0][0]                 \n",
      "                                                                 conv2d_143[0][0]                 \n",
      "                                                                 conv2d_145[0][0]                 \n",
      "                                                                 conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 16, 16, 128)  0           concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 16, 16, 32)   9248        conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 16, 16, 32)   25632       conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 16, 16, 32)   4128        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 16, 16, 128)  0           conv2d_147[0][0]                 \n",
      "                                                                 conv2d_149[0][0]                 \n",
      "                                                                 conv2d_151[0][0]                 \n",
      "                                                                 conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 16, 16, 128)  0           concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 16, 16, 32)   9248        conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 16, 16, 32)   25632       conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 16, 16, 32)   4128        max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 128)  0           conv2d_153[0][0]                 \n",
      "                                                                 conv2d_155[0][0]                 \n",
      "                                                                 conv2d_157[0][0]                 \n",
      "                                                                 conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 128)          0           concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          16512       global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           1290        activation_4[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 675,146\n",
      "Trainable params: 674,826\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Dense, BatchNormalization, Activation, Input, concatenate, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "def inception_layer(model):\n",
    "    filters = 32\n",
    "    \n",
    "    t1 = Conv2D(filters,(1,1),padding='same',activation='relu', kernel_regularizer=regularizers.l2(1E-3))(model)\n",
    "    \n",
    "    t2 = Conv2D(filters,(1,1),padding='same',activation='relu',kernel_regularizer=regularizers.l2(1E-3))(model)\n",
    "    t2 = Conv2D(filters,(3,3),padding='same',activation='relu',kernel_regularizer=regularizers.l2(1E-3))(t2)\n",
    "    \n",
    "    t3 = Conv2D(filters,(1,1),padding='same',activation='relu',kernel_regularizer=regularizers.l2(1E-3))(model)\n",
    "    t3 = Conv2D(filters,(5,5),padding='same',activation='relu',kernel_regularizer=regularizers.l2(1E-3))(t3)\n",
    "    \n",
    "    t4 = MaxPooling2D((3,3),strides=(1,1),padding='same')(model)\n",
    "    t4 = Conv2D(filters,(1,1),padding='same',activation='relu',kernel_regularizer=regularizers.l2(1E-3))(t4)\n",
    "    \n",
    "    return t1,t2,t3,t4\n",
    "\n",
    "inputs = Input(shape=(32,32,3))\n",
    "\n",
    "start = Conv2D(32,(3,3),padding='same')(inputs)\n",
    "start = BatchNormalization()(start)\n",
    "start = Activation('relu')(start)\n",
    "start = MaxPooling2D((2,2))(start)\n",
    "\n",
    "for i in range(13):\n",
    "    t1,t2,t3,t4 = inception_layer(start)\n",
    "    start = concatenate([t1,t2,t3,t4],axis=3)\n",
    "\n",
    "start = GlobalAveragePooling2D()(start)\n",
    "\n",
    "start = Dense(128)(start)\n",
    "start = BatchNormalization()(start)\n",
    "start = Activation('relu')(start)\n",
    "\n",
    "start = Dense(10, activation='softmax')(start)\n",
    "\n",
    "model = Model(inputs=inputs,outputs=start)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1562 [==============================] - 54s 35ms/step - loss: 2.0941 - acc: 0.3132 - val_loss: 3.3201 - val_acc: 0.2457\n",
      "Epoch 2/10\n",
      "1563/1562 [==============================] - 52s 33ms/step - loss: 1.5884 - acc: 0.4553 - val_loss: 3.9042 - val_acc: 0.1987\n",
      "Epoch 3/10\n",
      "1563/1562 [==============================] - 51s 33ms/step - loss: 1.4450 - acc: 0.5178 - val_loss: 3.1947 - val_acc: 0.2769\n",
      "Epoch 4/10\n",
      "1563/1562 [==============================] - 52s 33ms/step - loss: 1.3687 - acc: 0.5515 - val_loss: 6.2603 - val_acc: 0.2345\n",
      "Epoch 5/10\n",
      "1563/1562 [==============================] - 52s 33ms/step - loss: 1.3071 - acc: 0.5792 - val_loss: 4.6479 - val_acc: 0.3394\n",
      "Epoch 6/10\n",
      "1563/1562 [==============================] - 52s 33ms/step - loss: 1.2683 - acc: 0.5956 - val_loss: 12.1532 - val_acc: 0.2106\n",
      "Epoch 7/10\n",
      "1563/1562 [==============================] - 52s 33ms/step - loss: 1.2346 - acc: 0.6119 - val_loss: 6.1847 - val_acc: 0.2899\n",
      "Epoch 8/10\n",
      "1563/1562 [==============================] - 51s 33ms/step - loss: 1.2141 - acc: 0.6174 - val_loss: 7.5109 - val_acc: 0.1753\n",
      "Epoch 9/10\n",
      "1563/1562 [==============================] - 52s 33ms/step - loss: 1.1870 - acc: 0.6306 - val_loss: 6.8911 - val_acc: 0.1623\n",
      "Epoch 10/10\n",
      "1563/1562 [==============================] - 52s 33ms/step - loss: 1.1662 - acc: 0.6377 - val_loss: 13.7146 - val_acc: 0.2536\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-3 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "### Data Augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit(x_tr)\n",
    "\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_tr, y_tr, batch_size=32), steps_per_epoch=len(x_train) / 32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-3 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "### Data Augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit(x_tr)\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_train, y_train_vec, batch_size=32), \n",
    "                              steps_per_epoch=len(x_train) / 32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
