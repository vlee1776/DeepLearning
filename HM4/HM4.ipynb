{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 4: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Vincent Lee\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    samples = len(y)\n",
    "    ret = numpy.zeros((samples,num_class))\n",
    "    for i in range(samples):\n",
    "        ret[i,y[i]] = 1\n",
    "    return ret\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 7,905,706\n",
      "Trainable params: 7,899,434\n",
      "Non-trainable params: 6,272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, kernel_regularizer=regularizers.l2(1E-3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(128, kernel_regularizer=regularizers.l2(1E-3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-4 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vincent/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 1.8741 - acc: 0.4390 - val_loss: 1.8111 - val_acc: 0.4661\n",
      "Epoch 2/10\n",
      "1563/1562 [==============================] - 36s 23ms/step - loss: 1.4530 - acc: 0.5756 - val_loss: 1.2975 - val_acc: 0.6257\n",
      "Epoch 3/10\n",
      "1563/1562 [==============================] - 36s 23ms/step - loss: 1.2434 - acc: 0.6431 - val_loss: 1.3445 - val_acc: 0.6075\n",
      "Epoch 4/10\n",
      "1563/1562 [==============================] - 36s 23ms/step - loss: 1.0870 - acc: 0.6897 - val_loss: 1.0552 - val_acc: 0.6860\n",
      "Epoch 5/10\n",
      "1563/1562 [==============================] - 36s 23ms/step - loss: 0.9721 - acc: 0.7195 - val_loss: 1.2152 - val_acc: 0.6389\n",
      "Epoch 6/10\n",
      "1563/1562 [==============================] - 36s 23ms/step - loss: 0.8810 - acc: 0.7473 - val_loss: 0.8534 - val_acc: 0.7546\n",
      "Epoch 7/10\n",
      "1563/1562 [==============================] - 36s 23ms/step - loss: 0.8156 - acc: 0.7642 - val_loss: 0.9409 - val_acc: 0.7195\n",
      "Epoch 8/10\n",
      "1563/1562 [==============================] - 36s 23ms/step - loss: 0.7590 - acc: 0.7791 - val_loss: 0.7837 - val_acc: 0.7682\n",
      "Epoch 9/10\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 0.7047 - acc: 0.7944 - val_loss: 0.8596 - val_acc: 0.7397\n",
      "Epoch 10/10\n",
      "1563/1562 [==============================] - 36s 23ms/step - loss: 0.6575 - acc: 0.8067 - val_loss: 0.7141 - val_acc: 0.7883\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "### Data Augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit(x_tr)\n",
    "\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_tr, y_tr, batch_size=32), steps_per_epoch=len(x_train) / 32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-4 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.8671 - acc: 0.4377\n",
      "Epoch 2/10\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4502 - acc: 0.5798\n",
      "Epoch 3/10\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2431 - acc: 0.6428\n",
      "Epoch 4/10\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.0996 - acc: 0.6828\n",
      "Epoch 5/10\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 0.9868 - acc: 0.7166\n",
      "Epoch 6/10\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 0.9051 - acc: 0.7388\n",
      "Epoch 7/10\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 0.8390 - acc: 0.7542\n",
      "Epoch 8/10\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 0.7795 - acc: 0.7706\n",
      "Epoch 9/10\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 0.7279 - acc: 0.7854\n",
      "Epoch 10/10\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 0.6880 - acc: 0.7981\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "### Data Augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit(x_tr)\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_train, y_train_vec, batch_size=32), \n",
    "                              steps_per_epoch=len(x_train) / 32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 366us/step\n",
      "loss = 0.7499515717506409\n",
      "accuracy = 0.777899980545044\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
