{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 4: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Vincent Lee\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    samples = len(y)\n",
    "    ret = numpy.zeros((samples,num_class))\n",
    "    for i in range(samples):\n",
    "        ret[i,y[i]] = 1\n",
    "    return ret\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 717,994\n",
      "Trainable params: 716,330\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-3 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vincent/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "1563/1562 [==============================] - 15s 9ms/step - loss: 1.3110 - acc: 0.5276 - val_loss: 1.9568 - val_acc: 0.4727\n",
      "Epoch 2/10\n",
      "1563/1562 [==============================] - 14s 9ms/step - loss: 0.8834 - acc: 0.6903 - val_loss: 0.7812 - val_acc: 0.7184\n",
      "Epoch 3/10\n",
      "1563/1562 [==============================] - 14s 9ms/step - loss: 0.7417 - acc: 0.7436 - val_loss: 1.1944 - val_acc: 0.6260\n",
      "Epoch 4/10\n",
      "1563/1562 [==============================] - 14s 9ms/step - loss: 0.6567 - acc: 0.7721 - val_loss: 0.6250 - val_acc: 0.7882\n",
      "Epoch 5/10\n",
      "1563/1562 [==============================] - 14s 9ms/step - loss: 0.5907 - acc: 0.7959 - val_loss: 0.6231 - val_acc: 0.7842\n",
      "Epoch 6/10\n",
      "1563/1562 [==============================] - 14s 9ms/step - loss: 0.5506 - acc: 0.8109 - val_loss: 0.6290 - val_acc: 0.7905\n",
      "Epoch 7/10\n",
      "1563/1562 [==============================] - 15s 9ms/step - loss: 0.5062 - acc: 0.8274 - val_loss: 0.7907 - val_acc: 0.7567\n",
      "Epoch 8/10\n",
      "1563/1562 [==============================] - 14s 9ms/step - loss: 0.4905 - acc: 0.8328 - val_loss: 0.5311 - val_acc: 0.8252\n",
      "Epoch 9/10\n",
      "1563/1562 [==============================] - 14s 9ms/step - loss: 0.4589 - acc: 0.8424 - val_loss: 0.5175 - val_acc: 0.8257\n",
      "Epoch 10/10\n",
      "1563/1562 [==============================] - 15s 9ms/step - loss: 0.4303 - acc: 0.8534 - val_loss: 0.5268 - val_acc: 0.8355\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "### Data Augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit(x_tr)\n",
    "\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_tr, y_tr, batch_size=32), steps_per_epoch=len(x_train) / 32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXiU5fXw8e8hrAHZQRGQIAXZ1whaRGQVqkIVFyhWEQXrJS5U29JqlR9qa9Vaakt9CYhbg9RKRbAiZQBF60ZQFgkFkUUDqJFN2Qmc9497EiZhQibJPPPMZM7nuuaaebaZQ4A5ee7l3KKqGGOMMUVV8jsAY4wx8ckShDHGmLAsQRhjjAnLEoQxxpiwLEEYY4wJq7LfAURLw4YNNS0tze8wjDEmoaxcufJbVW0U7liFSRBpaWlkZWX5HYYxxiQUEdlW3DFrYjLGGBOWJQhjjDFhWYIwxhgTVoXpgwjn2LFj5OTkcPjwYb9DMadRvXp1mjVrRpUqVfwOxRgTokIniJycHM444wzS0tIQEb/DMWGoKrt27SInJ4eWLVv6HY4xJkSFbmI6fPgwDRo0sOQQx0SEBg0a2F2eMWWQmQlpaVCpknvOzIzu+1foOwjAkkMCsL8jY0ovMxPGj4eDB932tm1uG2D06Oh8hqd3ECIyREQ2iMgmEZkU5vg5IrJMRD4RkTUi8qPg/jQROSQiq4KP/+dlnMYYk2juu+9kcsh38KDbHy2eJQgRSQGmAUOB9sAoEWlf5LT7gZdVtRswEvhbyLHPVbVr8PEzr+L00q5du+jatStdu3blrLPOomnTpgXbR48ejeg9brrpJjZs2HDac6ZNm0ZmtO8tjTFx7YsvSre/LLxsYuoJbFLVzQAiMgcYDmSHnKNA7eDrOsAOD+MpUWamy75ffAHnnAOPPFK+W7UGDRqwatUqACZPnkytWrW49957C52jqqgqlSqFz9XPPvtsiZ9z++23lz1IY0xCOucc16wUbn+0eNnE1BT4MmQ7J7gv1GTgehHJAd4A7gg51jLY9PS2iPQJ9wEiMl5EskQkKzc3t1zB5rfnbdsGqifb87z4xXzTpk20b9+e0aNH06FDB3bu3Mn48eNJT0+nQ4cOTJkypeDciy66iFWrVpGXl0fdunWZNGkSXbp04cILL+Sbb74B4P7772fq1KkF50+aNImePXty3nnn8d577wFw4MABRowYQfv27bn66qtJT08vSF6hHnzwQc4//3w6duzIz372M/JXHNy4cSP9+/enS5cudO/ena1btwLwu9/9jk6dOtGlSxfui+a9rTHmtB55BFJTC+9LTXX7o8XvUUyjgOdUtRnwI+BFEakE7ATOCTY9/RyYLSK1i16sqhmqmq6q6Y0aha01FbFYtOeF+t///sfEiRPJzs6madOmPProo2RlZbF69WoWL15Mdnb2Kdfs27ePvn37snr1ai688EJmzZoV9r1VlY8++ojHH3+8INn85S9/4ayzziI7O5vf/va3fPLJJ2Gvveuuu1ixYgVr165l3759vPnmmwCMGjWKiRMnsnr1at577z0aN27MggULWLhwIR999BGrV6/mnnvuidJPx5j45vXooUiMHg0ZGdCiBYi454yM6HVQg7cJYjvQPGS7WXBfqJuBlwFU9X2gOtBQVY+o6q7g/pXA50AbD2ONSXteqFatWpGenl6w/dJLL9G9e3e6d+/O+vXrwyaIGjVqMHToUAB69OhR8Ft8UVddddUp57z77ruMHDkSgC5dutChQ4ew1y5ZsoSePXvSpUsX3n77bdatW8eePXv49ttvueKKKwA3sS01NZVAIMDYsWOpUaMGAPXr1y/9D8KYBBPL1oaSjB4NW7fCiRPuOZrJAbxNECuA1iLSUkSq4jqh5xc55wtgAICItMMliFwRaRTs5EZEzgVaA5s9jLXYdrtotueFqlmzZsHrzz77jD//+c8sXbqUNWvWMGTIkLDzAqpWrVrwOiUlhby8vLDvXa1atRLPCefgwYNMmDCBV199lTVr1jB27Fibn2BMEbFubfCTZwlCVfOACcAiYD1utNI6EZkiIsOCp90DjBOR1cBLwBh1jd4XA2tEZBXwCvAzVd3tVawQm/a84nz33XecccYZ1K5dm507d7Jo0aKof0bv3r15+eWXAVi7dm3YO5RDhw5RqVIlGjZsyPfff8/cuXMBqFevHo0aNWLBggWAm4B48OBBBg0axKxZszh06BAAu3d7+ldkTFyIdWuDnzydKKeqb+A6n0P3PRDyOhvoHea6ucBcL2MrKv/WLJqjmCLVvXt32rdvT9u2bWnRogW9e5/yIym3O+64gxtuuIH27dsXPOrUqVPonAYNGnDjjTfSvn17mjRpQq9evQqOZWZmcuutt3LfffdRtWpV5s6dy+WXX87q1atJT0+nSpUqXHHFFTz00ENRj92YeBKL0UNxI3+YZaI/evTooUVlZ2efsi9ZHTt2TA8dOqSqqhs3btS0tDQ9duyYz1GdZH9XJhJ//7tqixaqIu7573/3J4bUVFXXA+Eeqan+xKKHD6tmZ6uuXFnmtwCytJjv1QpfasM4+/fvZ8CAAeTl5aGqTJ8+ncqV7a/fJI5YlJaIRMxbG1Rh+3bYuBE2bCj8vGWL66Hu2RM+/DDqHy0aHOee6NLT07XokqPr16+nXbt2PkVkSsP+rkxJ0tLCN+20aOFG8CS8774LnwQ2boQDB06eV6MGtGkD55138rl9e+jevUwfKyIrVTU93DH7FdIYE5FoVxoorQrROXzsGGzeHD4RfPXVyfPyJ1i0aQMXX1w4ITRt6o7HgCUIY0yJ4qF5J2E6h1Xdl33RBLBhg0sOx4+fPLdhQ/fFP3Ro4TuCVq0gOFzdT5YgjDElOt3Y/1gliEceKZykoBxD0VVd2315H/v2hW8S+v77k59VvTq0bg1dusA115xMBG3aQJxPLrUEYYwpUTw07+QnomUT5/PL3Hs5I+UgdaqeIPWeEzCxFF/qXvS75te6aNMGxowp3CTUvHnMmoSizRKEh/r168ekSZO49NJLC/ZNnTqVDRs28PTTTxd7Xa1atdi/fz87duzgzjvv5JVXXjnlnEsuuYQnnniiULmOoqZOncr48eNJDc4A/NGPfsTs2bOpW7duOf5UJhnFS/PO6Eb/YfS+a6BjG+h1sfviLe9DpOzX1qzpkkCrVq7zuIKxBOGhUaNGMWfOnEIJYs6cOTz22GMRXX/22WeHTQ6Rmjp1Ktdff31BgnjjjTdKuMKY8KLavFNW77wDP/4xtGsHy5ZBvXox/PDklJj3PQni6quv5t///nfB4kBbt25lx44d9OnTp2BeQvfu3enUqROvvfbaKddv3bqVjh07Aq4MxsiRI2nXrh1XXnllQXkLgNtuu62gVPiDDz4IwFNPPcWOHTvo168f/fr1AyAtLY1vv/0WgCeffJKOHTvSsWPHglLhW7dupV27dowbN44OHTowePDgQp+Tb8GCBfTq1Ytu3boxcOBAvv76a8DNtbjpppvo1KkTnTt3LijV8eabb9K9e3e6dOnCgAEDovKzNbEVi8qhp5WVBZdd5m5Z/vMfSw4xkjx3EHffDWHWPyiXrl0h+OUaTv369enZsycLFy5k+PDhzJkzh2uvvRYRoXr16rz66qvUrl2bb7/9lgsuuIBhw4YVuz7z008/TWpqKuvXr2fNmjV0Dxnz/Mgjj1C/fn2OHz/OgAEDWLNmDXfeeSdPPvkky5Yto2HDhoXea+XKlTz77LN8+OGHqCq9evWib9++1KtXj88++4yXXnqJGTNmcO211zJ37lyuv/76QtdfdNFFfPDBB4gIM2fO5LHHHuOPf/wjDz30EHXq1GHt2rUA7Nmzh9zcXMaNG8fy5ctp2bKl1WtKYKNHx3ZYa4FPP4VLL4UGDSAQgMaNfQgiOdkdhMfym5nANS+NGjUKcCVOfvOb39C5c2cGDhzI9u3bC34TD2f58uUFX9SdO3emc+fOBcdefvllunfvTrdu3Vi3bl3YQnyh3n33Xa688kpq1qxJrVq1uOqqq3jnnXcAaNmyJV27dgWKLymek5PDpZdeSqdOnXj88cdZt24dAIFAoNDqdvXq1eODDz7g4osvpmXLloCVBC+LeFh7wDeffQYDB7qRQEuWQLNmfkeUVJLnDuI0v+l7afjw4UycOJGPP/6YgwcP0qNHD8AVv8vNzWXlypVUqVKFtLS0MpXW3rJlC0888QQrVqygXr16jBkzplwluquFjL1OSUkJ28R0xx138POf/5xhw4bx1ltvMXny5DJ/njm9eJh/4Jtt22DAADdvYNkyOPdcvyNKOnYH4bFatWrRr18/xo4dW3D3AG51uMaNG1OlShWWLVvGtnBDREJcfPHFzJ49G4BPP/2UNWvWAK5UeM2aNalTpw5ff/01CxcuLLjmjDPO4PvQ8dhBffr0Yd68eRw8eJADBw7w6quv0qdP2FVdw9q3bx9Nm7rVY59//vmC/YMGDWLatGkF23v27OGCCy5g+fLlbNmyBbCS4KWVTGsPFLJzp7tz+O471+dgZVh8YQkiBkaNGsXq1asLJYjRo0eTlZVFp06deOGFF2jbtu1p3+O2225j//79tGvXjgceeKDgTqRLly5069aNtm3b8pOf/KRQqfDx48czZMiQgk7qfN27d2fMmDH07NmTXr16ccstt9CtW7eI/zyTJ0/mmmuuoUePHoX6N+6//3727NlDx44d6dKlC8uWLaNRo0ZkZGRw1VVX0aVLF6677rqIP8fEx/yDmNu1CwYNckli4UIoxb9NE11WrM/EBfu7Cq/CF6grat8+16z06afwxhvQv7/fEVV4pyvWZ3cQxsQxP1c6jLkDB+Dyy2H1apg715JDHPA0QYjIEBHZICKbRGRSmOPniMgyEflERNaIyI9Cjv06eN0GEbm06LXGJAPf5x/EypEjcOWV8N57rmf+ssv8jsjg4SgmEUkBpgGDgBxghYjMV7fMaL77cWtVPy0i7XHLk6YFX48EOgBnAwERaaOqxyklVS12boGJDxWlmdMrvs0/iJVjx+C662DxYpg1C6691u+ITJCXdxA9gU2qullVjwJzgOFFzlGgdvB1HWBH8PVwYI6qHlHVLcCm4PuVSvXq1dm1a5d9AcUxVWXXrl1Ur17d71BOkdTzD2Ll+HFX3O611+Avf4GbbvI7IhPCy3kQTYEvQ7ZzgF5FzpkM/EdE7gBqAgNDrv2gyLVNi36AiIwHxgOcE6ZqWLNmzcjJySE3N7dsfwITE9WrV6dZnE2ASur5B7GiCrfdBrNnw+9/DxMm+B2RKcLviXKjgOdU9Y8iciHwooh0jPRiVc0AMsCNYip6vEqVKgUzeI0pjXhY/6BCU4V77oEZM+A3v4FJp3RRmjjgZYLYDjQP2W4W3BfqZmAIgKq+LyLVgYYRXmuMZ5Jy/kEsTZ4Mf/oT3HknPPyw39GYYnjZB7ECaC0iLUWkKq7TeX6Rc74ABgCISDugOpAbPG+kiFQTkZZAa+AjD2M1ppDi1jmIu+UtE9Hjj8OUKTB2rEsSNogkbnl2B6GqeSIyAVgEpACzVHWdiEwBslR1PnAPMENEJuI6rMeo61FeJyIvA9lAHnB7WUYwGVNWMV3/QBX27nUzh3fudOsZ57/O387NhUsucc0xTZp4EESMPP00/PKXbtRSRkbCrrSWLCr0TGqTwBYudD3FtWtD3bonH3XqhH/twSiozEzX5/DFF+7O4ZFHStn/kJcH33wT/gu/6PaRI6den5rqkkGTJlCrlhsGWrWq68z91a9c+etE8uKLcMMNcMUVbiJclSp+R2Q4/UxqSxAm/qi6ZRx37nRf/Pv2uS/b06lWrXDCOF0yCbdds2bkTR2HDhX/ZR+6LzfXrYFcVIMGcNZZJ7/8mzQJv33GGYVj2rTJtd3Pnu0Sxs9/7h61a5/6GfFm7lw3v6FfP3j9dU8SuikbSxAmsSxd6urxvPAC/PSnLmEcPOiaYfbtc8/5j9Dt0x0rqQR6SsrJpFE0sRw5UvjLf9++8Nfnf8mf7sv/zDNdMiuPdevggQfgX/+C+vXd3cSECafW5IgXCxfC8OFw/vmwaJFLbiZuWIIwiSV/Vu327dFbCP7IkeKTyekSy9697gu9pN/2GzaMfXv6ypVw//3w5psuhvvug3Hjyp+Aountt2HIEFeue+lSl3RNXLEEYRLHN9+4VcNuv92NcDEle/ddlxyWL3edJQ88ADfeCJV9nub04YduTYfmzV2iaNTI33hMWFbN1SSOZ591tXnypy2bkl10Ebz1lmu+OfNMuOUWaN8eXnopfB9ILKxZA0OHuvWjAwFLDgnKEoSJHydOwIwZfHNeH9KGtrMaSKUhAoMHu9/a581zncA/+Ql07erqHMWypWDDBrfgT82abh3ps8+O3WebqLIEYeLH0qXw+edM2nIr27a577T8GkiWJCIk4jqEV61yo50OH4Yf/xguuMD163idKLZudc1K4O4c0tK8/TzjKUsQJn5Mn87uSg2YfXREod1JsQZztFWqBKNGQXY2zJzpRl8NHuwm2737rjefuWOHG3124IBLRued583nmJixBGHiw1dfwbx5PHfiRo5w6hh5q4FURpUrw803w8aNrpz2hg3Qp4/rH1i5Mnqfk5vrmpW++caNqurcOXrvbXxjCcLEh+eeg7w8/n32uLCHrQZSOVWr5uZKbN4Mf/gDfPQRpKfDiBFuXkV57N0Ll17q3vv116FnqZduMXHKEoTxX7Bzmr59GftY2+RZg9kPqamuFtLmzfDgg64pqFMnNyHx889L/37797vlQT/91E3c69s3+jEb31iCMP4LBNwX1q23Js8azH6rU8eV7diyBe6915XCaNsWbr0VvvyyxMsB1wE+fDh88IEbUjt0qKchm9iziXLGfyNGuEleOTnxNQs4mezcCb/7HUyf7jq4f/Yz+PWv3byKcI4dc39vCxbA88+7InwmIdlEORO/du504/THjLHk4KcmTVwn9mefudu1v/4Vzj3XlRffs6fwucePuyapBQvgb3+z5FCBWYIw/nr2WfeFMy5857SJsRYt4Jln3PDYYcPcWtEtW7pV377/3vUXjR8P//gHPPaYW1PaVFjWxGT8c+IEtGrlvoCWLvU7GhPOmjXw29/C/PmuIGGvXvDvf7t6T//3f35HZ6LAmphMfPrPf9zM21tv9TsSU5zOnV0T4IcfQrduLjlMnOg6uE2F52m5RxEZAvwZt+ToTFV9tMjxPwH9gpupQGNVrRs8dhxYGzz2haoO8zJW44Pp010Rtyuv9DsSU5KePV1Cz8mBpk1tHekk4VmCEJEUYBowCMgBVojIfFXNzj9HVSeGnH8H0C3kLQ6palev4jM+27HDdXLec49bRtMkhmbN/I7AxJCXTUw9gU2qullVjwJzgOGnOX8U8JKH8Zh4MmuWdU4bE+e8TBBNgdAZNznBfacQkRZASyC0p7K6iGSJyAci8uNirhsfPCcrNzc3WnEnrcxMV3zT8zLbx4+7mdMDBsAPfuDRhxhjysvnJacKjAReUdXjIftaqOp2ETkXWCoia1W1UC0AVc0AMsCNYopduBVPZqYbvXjwoNvOL7MNHsxiXrTIVd974okov7ExJpq8vIPYDjQP2W4W3BfOSIo0L6nq9uDzZuAtCvdPmCi7776TySGfZ2W2p093K40NP12LozHGb14miBVAaxFpKSJVcUlgftGTRKQtUA94P2RfPRGpFnzdEOgNZBe91kRPceW0o15mOyfHVfwcO9Y6p42Jc54lCFXNAyYAi4D1wMuquk5EpohI6JDVkcAcLTxjrx2QJSKrgWXAo6Gjn0z0FVdOO+pltmfNchPkbrklym9sjIk2m0ltgFP7IMBVho5qJdXjx92s6bZt3Zh6Y4zvbCa1KVFMymwvXOhKSdvMaWMSgt1BmNi54grIynIdG1Wq+B2NMQa7gzDx4Msv4Y03XOe0JQdjEoIlCBMbzzwDqtY5bUwCsQRhvJeXBzNnwuDBrpPaGJMQLEEY773xBmzfbp3TxiQYSxDGe9OnuyUtL7/c70iMMaVgCcJ464sv3PBW65w2JuFYgjDemjnTPVtZb2MSjiWIeJGXB3PnwrFjfkcSPXl5bvTSkCFu5p0xJqFYgogXr74KV19dsdb6ff11t3KcdU4bk5AsQcSLxYvd8+9/D++8428s0TJ9Opx9Nlx2md+RGGPKwBJEvAgEYOBAaNUKfvpT2LfP74jKZ+tWtzDQzTdD5XhZl8oYUxqWIOLB5s2wZYtbQOfvf3drJkyY4HdU5TNzpqv6ZzOnjUlYliDiQSDgngcOhF694IEHXKKYM8ffuMrq2DHXOT10qAcLShhjYsUSRDwIBKBpUzjvPLf9m9/AhRfCbbe5IneJZsEC+Oor65w2JsFZgvDbiROwdKm7exBx+ypXhhdfdMNEb7zRnZNIpk+HZs3cHYQxJmF5miBEZIiIbBCRTSIyKczxP4nIquBjo4jsDTl2o4h8Fnzc6GWcvlq9GnbtcgkiVKtW8NRTsGwZPPmkP7GVxZYtbrU465w2JuF59j9YRFKAacAgIAdYISLzQ9eWVtWJIeffAXQLvq4PPAikAwqsDF67x6t4fZPf/9C//6nHxoyBf//bNTkNHAhdu8Y0tDKZMQMqVbLOaWMqgBLvIETkDhGpV4b37glsUtXNqnoUmAMMP835o4CXgq8vBRar6u5gUlgMDClDDPEvEID27d18gaJEXHNNw4Zu7c9Dh2IfX2kcOwazZrl5D82a+R2NMaacImliOhP32//LwSYjifC9mwKhPaw5wX2nEJEWQEtgaWmuFZHxIpIlIlm5ubkRhhVHDh92k+KKNi+FatAAnn8esrPhV7+KXWxl8dpr8PXX1jltTAVRYoJQ1fuB1sAzwBjgMxH5nYi0imIcI4FXVPV4aS5S1QxVTVfV9EaNGkUxnBh5/313V3C6BAEwaBDcfTf85S/w5puxia0spk+H5s1d7SVjTMKLqJNaVRX4KvjIA+oBr4jIY6e5bDvQPGS7WXBfOCM52bxU2msTVyAAKSn846u+pKW5pvu0NMjMDHPu738PHTvCTTdBPN4tff65+/PccgukpPgdjTEmCiLpg7hLRFYCjwH/BTqp6m1AD2DEaS5dAbQWkZYiUhWXBOaHef+2uITzfsjuRcBgEakX7P8YHNxXsSxZQu65vRh7d222bXNLNm/bBuPHh0kS1au7nbt3uxNUfQm5WDNmuMRw881+R2KMiZJI7iDqA1ep6qWq+k9VPQagqieAYpcIU9U8YALui3098LKqrhORKSIyLOTUkcCc4F1K/rW7gYdwSWYFMCW4r+LYuxdWrGD2NwM5eLDwoYMH4b77wlzTubO7k5g3z3UGx4ujR+HZZ92KcU3DdjMZYxKQaAm/iYrIBcA6Vf0+uF0baKeqH8Ygvoilp6drVlaW32FEbt48uPJKLmY579DnlMMixcyPO3ECBg+GDz6ATz6B1q29j7UkL78M113n1p62yXHGJBQRWamq6eGORXIH8TSwP2R7f3CfKY9AAFJT2XlOr7CHiy1hVKkSPPccVK0K118fHwsMZWS4BYEGD/Y7EmNMFEWSIKRI888JPJxglzQCAejbl8m/q0pqauFDqanwyCOnubZZMzdi6KOP4OGHPQ2zRJs2wZIl1jltTAUUSYLYLCJ3ikiV4OMuYLPXgVVoX34JGzbAwIGMHn3yF3AR95yR4ebFndY117g6TQ8/7IbL+iUjwyWGsWP9i8EY44lI+iAaA08B/XFlL5YAd6vqN96HF7mE6oN47jk3XHX1atfxXFbffefKb4jAqlVwxhlRCzEiR464u5k+feBf/4rtZxtjoqJcfRCq+o2qjlTVxqp6pqr+JN6SQ8JZsgQaN3bzGsqjdm1X9XXrVrjrrqiEViqvvgrffmszp42poErsSxCR6sDNQAegev5+VbU2hbJQdf0PAwa4Dufy6t3bFfN7+GFXA2nE6aamRFlGhpvZN2hQ7D7TGBMzkXxDvQichSug9zZuVvP3XgZVoWVnu8V0SiqvURoPPADnn+8m0G2P0YTzjRtdKfJx46KT6IwxcSeS/9k/UNXfAgdU9XngMiD82ExTsvzy3gMGRO89q1RxS5QePuz6NmKxwFBGhlvvwTqnjamwIkkQ+QPt94pIR6AO0Ni7kCq4QAB+8AM3XCma2rSBP/0JFi92Cw156fBh19E+fDicdZa3n2WM8U0kCSIjWA/pflwtpWzgD55GVVEdOwZvvRXd5qVQ48bBsGEwaRKsXevNZ4AbsbRrl3VOG1PBnTZBiEgl4DtV3aOqy1X13OBopukxiq9i+egj2L/fuwQhAjNnQt26biLF4cPefE5GBpx7bnSbyYwxcee0CSI4a/qXMYql4luyxH2J9+vn3Wc0auQK561dW0zFv3L63//g7betc9qYJBDJ//CAiNwrIs1FpH7+w/PIKqJAAHr0gPoe//iGDoXbb4cnnzzZKR4t+Z3TN90U3fc1xsSdSBLEdcDtwHJgZfCRIFOW48j+/a4khlfNS0U99hi0a+fKceyOUqX0w4fd8qdXXglnnhmd9zTGxK1IZlK3DPM4NxbBVSjLl0NeXuza7VNT3dDX3FzXmRyNBYZeecUlG+ucNiYpRDKT+oZw+1X1heiHU4EFAlCtmpv5HCvdu8NDD7lRTS+84O4myiMjA1q18rYPxRgTNyJpYjo/5NEHmAwMO90FJoxAAC66CGrUiO3n3nsv9O0LEybA5nIU4c3OhnfecbO1rXPamKQQSRPTHSGPcUB3oFYkby4iQ0Rkg4hsEpFJxZxzrYhki8g6EZkdsv+4iKwKPk5ZyzqhfP21G1UUq/6HUCkp7u4hJQV++lPXzFUWGRluxvaYMVENzxgTv8ryq+ABoGVJJ4lICjANGAq0B0aJSPsi57QGfg30VtUOwN0hhw+patfgI7HvWJYudc9+JAhwy9M9/TS89x48+mjprz90yHVOX3WVq0JrjEkKkfRBLMCtAwEuobQHXo7gvXsCm1R1c/B95gDDcTOx840DpqnqHnClxSMPPYEEAlCvHnTr5l8Mo0bB66/D5MluadCePSO/9p//hL17rXPamCQTydKhT4S8zgO2qWpOBNc1Bb4M2c7h1CJ/bQBE5L9ACrs/2fcAABF/SURBVDBZVd8MHqsuIlnBz3xUVecV/QARGQ+MBzin2EWcfabq6iP17+//kpzTpsG777pZ1p98ArUiail0zUutW8Mll3ganjEmvkTSxPQF8KGqvq2q/wV2iUhalD6/MtAauAQYBcwQkbrBYy2Cqxz9BJgqIq2KXqyqGaqarqrpjRo1ilJIUbZpk1tiNB7KUtSt6/ojPv8cfv7zyK5Ztw7++1/XOS3ibXzGmLgSSYL4JxBaP/p4cF9JtgPNQ7abBfeFygHmq+oxVd0CbMQlDFR1e/B5M/AW4GP7TDnkz2T2q/+hqL594Ze/hBkz4LXXSj5/+nSoWtU6p41JQpEkiMqqejR/I/i6agTXrQBai0hLEakKjMRVgw01D3f3gIg0xDU5bRaReiJSLWR/bwr3XSSOQMB1Ev/gB35HctKUKa4/5JZb3OJFxTl40N1xjBgBDRvGLj5jTFyIJEHkikjBKCIRGQ58W9JFqpoHTAAWAeuBl1V1nYhMCXm/Rbgmq2xgGfALVd0FtAOyRGR1cP+jqpp4CeL4cTeCaeDA+GqeqVoVMjNd+Y+bbip+lvU//wn79lnntDFJSrSEEgzBtv9M4OzgrhzgBlXd5HFspZKenq5ZWXFWIioryy0FOnu2G0UUb/72N1fU769/dc9F/fCHrrTG+vXxleCMMVEjIiuD/b2niGSi3OeqegFueGt7Vf1hvCWHuJXf/9C/v79xFOe221zl13vvdTOlQ61d64oLWue0MUmrxAQhIr8Tkbqqul9V9wf7Bx6ORXAJLxCAzp3jt/KpCMya5Ya7jh4NR4+ePDZ9uqsdVd76TcaYhBVJH8RQVd2bvxGc1PYj70KqIA4dcnMO4mX0UnHOOgueeQZWrYLf/tbtO3AAXnwRrr4aGjTwNz5jjG8imSiXIiLVVPUIgIjUAKp5G1YF8N//wpEj8TH/oSTDhrmmpMcfd01OW7bAd9+5fcaYpBVJgsgElojIs4AAY4DnvQyqQggE3MprF1/sdySRefJJWLYMbrjB3TW0awd9+vgdlTHGRyUmCFX9Q3C46UBcTaZFQAuvA0t4gQBceGHk5Sz8VrOmG/r6wx+6md9/+pN1ThuT5CKt5vo1LjlcA/THzWswxdm9Gz7+OP77H4o6/3z4wx+gRQt3J2GMSWrF3kGISBtcfaRRuIlx/8DNm7DlxEqybJmbfJZoCQJcjaa777ZFgYwxp21i+h/wDnB5/rwHEZkYk6gSXSAAZ5zhfiNPRJYcjDGcvonpKmAnsExEZojIAFwntSlJIOBKY1ep4nckxhhTZsUmCFWdp6ojgba4ekh3A41F5GkRGRyrABPO1q2uxHciDG81xpjTiKTUxgFVna2qV+BKdn8C/MrzyBLVkiXuORH7H4wxJkSpGptVdU9wkR779bg4gYCbndy+fcnnGmNMHLPeyGg6ccLdQcRbeW9jjCkDSxDR9OmnkJtrzUvGmArBEkQ05Zf3tg5qY0wFYAkimgIBaNsWmjXzOxJjjCk3TxOEiAwRkQ0isklEJhVzzrUiki0i60Rkdsj+G0Xks+Aj/hclOHoU3n7b7h6MMRVGJNVcy0REUoBpwCDcMqUrRGR+6NrSItIa+DXQW1X3iEjj4P76wINAOq4G1MrgtXu8irfcPvgADh60/gdjTIXh5R1ET2CTqm5W1aPAHGB4kXPGAdPyv/hV9Zvg/kuBxaq6O3hsMTDEw1jLLxBwJSouucTvSIwxJiq8TBBNgS9DtnOC+0K1AdqIyH9F5AMRGVKKaxGR8SKSJSJZubm5UQy9DJYscbWX6tb1Nw5jjIkSvzupKwOtgUtwVWNniEjE37DBSXvpqpreqFEjj0KMwHffwYcfWvOSMaZC8TJBbAeah2w3C+4LlQPMV9VjqroF2IhLGJFcGz/efhuOH7cEYYypULxMECuA1iLSUkSqAiOB+UXOmYe7e0BEGuKanDbjVq0bLCL1RKQeMDi4Lz4FAlCjhltBzhhjKgjPRjGpap6ITMB9sacAs1R1nYhMAbJUdT4nE0E2cBz4haruAhCRh3BJBmCKqu72KtZyCwTc+s3VqvkdiTHGRI2oqt8xREV6erpmZWXF/oN37ICmTeGxx+AXv4j95xtjTDmIyEpVTQ93zO9O6sRn5b2NMRWUJYjyWrIEGjSALl38jsQYY6LKEkR5qLr+hwEDbB1nY0yFY99q5bFhA2zfbs1LxpgKyRJEeeSX97YEYYypgCxBlEcgAOeeCy1b+h2JMcZEnSWIssrLg2XLrLy3MabCsgRRVllZrgaTNS8ZYyooSxBllT//oX9/f+MwxhiPWIIoq0AAunWDhg39jsQYYzxhCaIsDhyA996z5iVjTIVmCaIs3n3XrUFtCcIYU4FZgiiLQACqVoWLLvI7EmOM8YwliLIIBOCHP4TUVL8jMcYYz1iCKK3cXFi1ypqXjDEVniWI0lq2zD1bgjDGVHCWIEorEIA6daBHD78jMcYYT3maIERkiIhsEJFNIjIpzPExIpIrIquCj1tCjh0P2V90LWv/BALQrx9U9my1VmOMiQuefcuJSAowDRgE5AArRGS+qmYXOfUfqjohzFscUtWuXsVXJps3w5YtcM89fkdijDGe8/IOoiewSVU3q+pRYA4w3MPP856V9zbGJBEvE0RT4MuQ7ZzgvqJGiMgaEXlFRJqH7K8uIlki8oGI/DjcB4jI+OA5Wbm5uVEMvRiBADRtCm3aeP9ZxhjjM787qRcAaaraGVgMPB9yrIWqpgM/AaaKSKuiF6tqhqqmq2p6o0aNvI30xAlYutTdPYh4+1nGGBMHvEwQ24HQO4JmwX0FVHWXqh4Jbs4EeoQc2x583gy8BXTzMNaSrV4Nu3ZZ85IxJml4mSBWAK1FpKWIVAVGAoVGI4lIk5DNYcD64P56IlIt+Loh0Bso2rkdW/n9D7ZAkDEmSXg2iklV80RkArAISAFmqeo6EZkCZKnqfOBOERkG5AG7gTHBy9sB00XkBC6JPRpm9FNsBQLQoQM0aVLyucYYUwGIqvodQ1Skp6drVlaWN29++DDUrw/jx8PUqd58hjHG+EBEVgb7e0/hdyd1Ynj/fTh0yPofjDFJxRJEJAIBSEmBiy/2OxJjjImZpE8QmZmQlgaVKrnnzMwwJwUC0KsX1K4d4+iMMcY/SZ0gMjNdt8K2baDqnsePL5Ik9u6FrCxrXjLGJJ2kThD33QcHDxbed/Cg21/grbfcJDlLEMaYJJPUCeKLLyLYHwhAzZquickYY5JIUieIc86JYH8gAH37ujWojTEmiSR1gnjkkVOXlU5NdfsB+PJL2LDBmpeMMUkpqRPE6NGQkQEtWrj6ey1auO3Ro4MnLFninq28hjEmCSX9smijR4ckhKICAWjcGDp2jGlMxhgTD5L6DuK0VN0dxIABbpKEMcYkGfvmK052Nnz1lfU/GGOSliWI4tjyosaYJGcJojiBALRuXfxYWGOMqeAsQYRz7JibQW13D8aYJGYJIpyPPoL9+y1BGGOSmiWIcAIBNzHikkv8jsQYY3zjaYIQkSEiskFENonIpDDHx4hIroisCj5uCTl2o4h8Fnzc6GWcp1iyBHr0cKvIGWNMkvJsopyIpADTgEFADrBCROaHWVv6H6o6oci19YEHgXRAgZXBa/d4FW+B/fvdCnL33uv5RxljTDzz8g6iJ7BJVTer6lFgDjA8wmsvBRar6u5gUlgMDPEozsKWL4e8POt/MMYkPS8TRFPgy5DtnOC+okaIyBoReUVEmpfmWhEZLyJZIpKVm5sbnagDAaheHXr3js77GWNMgvK7k3oBkKaqnXF3Cc+X5mJVzVDVdFVNb9SoUXQiCgTgootckjDGmCTmZYLYDjQP2W4W3FdAVXep6pHg5kygR6TXeuKrr2DtWmteMsYYvE0QK4DWItJSRKoCI4H5oSeISJOQzWHA+uDrRcBgEaknIvWAwcF93lq61D1beW9jjPFuFJOq5onIBNwXewowS1XXicgUIEtV5wN3isgwIA/YDYwJXrtbRB7CJRmAKaq626tYCyxZAvXqQbdunn+UMcbEO1FVv2OIivT0dM3Kyir7G6i6FYN69oRXXoleYMYYE8dEZKWqpoc75ncndfzYtMktMWr9D8YYA1iCOMnKextjTCGWIPIFAq6JqVUrvyMxxpi4YAkC4PhxN4Jp4EBXpM8YY4wlCAA+/hj27rXhrcYYE8ISBLjhrQD9+/sbhzHGxBFLEOD6Hzp3hjPP9DsSY4yJG5YgDh2Cd9+10UvGGFOEJYi9e2HECLj8cr8jMcaYuOJZqY2E0aQJZGb6HYUxxsQdu4MwxhgTliUIY4wxYVmCMMYYE5YlCGOMMWFZgjDGGBOWJQhjjDFhWYIwxhgTliUIY4wxYVWYJUdFJBfYVo63aAh8G6VwEp39LAqzn0dh9vM4qSL8LFqoaqNwBypMgigvEckqbl3WZGM/i8Ls51GY/TxOqug/C2tiMsYYE5YlCGOMMWFZgjgpw+8A4oj9LAqzn0dh9vM4qUL/LKwPwhhjTFh2B2GMMSYsSxDGGGPCSvoEISJDRGSDiGwSkUl+x+MnEWkuIstEJFtE1onIXX7H5DcRSRGRT0Tkdb9j8ZuI1BWRV0TkfyKyXkQu9DsmP4nIxOD/k09F5CURqe53TNGW1AlCRFKAacBQoD0wSkTa+xuVr/KAe1S1PXABcHuS/zwA7gLW+x1EnPgz8KaqtgW6kMQ/FxFpCtwJpKtqRyAFGOlvVNGX1AkC6AlsUtXNqnoUmAMM9zkm36jqTlX9OPj6e9wXQFN/o/KPiDQDLgNm+h2L30SkDnAx8AyAqh5V1b3+RuW7ykANEakMpAI7fI4n6pI9QTQFvgzZziGJvxBDiUga0A340N9IfDUV+CVwwu9A4kBLIBd4NtjkNlNEavodlF9UdTvwBPAFsBPYp6r/8Teq6Ev2BGHCEJFawFzgblX9zu94/CAilwPfqOpKv2OJE5WB7sDTqtoNOAAkbZ+diNTDtTa0BM4GaorI9f5GFX3JniC2A81DtpsF9yUtEamCSw6Zqvovv+PxUW9gmIhsxTU99heRv/sbkq9ygBxVzb+jfAWXMJLVQGCLquaq6jHgX8APfY4p6pI9QawAWotISxGpiutkmu9zTL4REcG1Ma9X1Sf9jsdPqvprVW2mqmm4fxdLVbXC/YYYKVX9CvhSRM4L7hoAZPsYkt++AC4QkdTg/5sBVMBO+8p+B+AnVc0TkQnAItwohFmqus7nsPzUG/gpsFZEVgX3/UZV3/AxJhM/7gAyg79MbQZu8jke36jqhyLyCvAxbvTfJ1TAshtWasMYY0xYyd7EZIwxphiWIIwxxoRlCcIYY0xYliCMMcaEZQnCGGNMWJYgjCmBiBwXkVUhj6jNIBaRNBH5NFrvZ0w0JfU8CGMidEhVu/odhDGxZncQxpSRiGwVkcdEZK2IfCQiPwjuTxORpSKyRkSWiMg5wf1nisirIrI6+MgvzZAiIjOCawv8R0RqBM+/M7g2xxoRmePTH9MkMUsQxpSsRpEmputCju1T1U7AX3HVXwH+Ajyvqp2BTOCp4P6ngLdVtQuujlH+rP3WwDRV7QDsBUYE908CugXf52de/eGMKY7NpDamBCKyX1Vrhdm/FeivqpuDRQ6/UtUGIvIt0ERVjwX371TVhiKSCzRT1SMh75EGLFbV1sHtXwFVVPVhEXkT2A/MA+ap6n6P/6jGFGJ3EMaUjxbzujSOhLw+zsm+wctwKx52B1YEF6YxJmYsQRhTPteFPL8ffP0eJ5efHA28E3y9BLgNCta6rlPcm4pIJaC5qi4DfgXUAU65izHGS/YbiTElqxFS3Rbcusz5Q13ricga3F3AqOC+O3Arr/0CtwpbftXTu4AMEbkZd6dwG241snBSgL8Hk4gAT9kSnybWrA/CmDIK9kGkq+q3fsdijBesickYY0xYdgdhjDEmLLuDMMYYE5YlCGOMMWFZgjDGGBOWJQhjjDFhWYIwxhgT1v8HS68OQYIdC38AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-4 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1562 [==============================] - 13s 8ms/step - loss: 1.5558 - acc: 0.4438\n",
      "Epoch 2/10\n",
      "1563/1562 [==============================] - 12s 8ms/step - loss: 1.1882 - acc: 0.5805\n",
      "Epoch 3/10\n",
      "1563/1562 [==============================] - 12s 8ms/step - loss: 1.0441 - acc: 0.6307\n",
      "Epoch 4/10\n",
      "1563/1562 [==============================] - 12s 8ms/step - loss: 0.9393 - acc: 0.6692\n",
      "Epoch 5/10\n",
      "1563/1562 [==============================] - 12s 8ms/step - loss: 0.8639 - acc: 0.6951\n",
      "Epoch 6/10\n",
      "1563/1562 [==============================] - 13s 8ms/step - loss: 0.8021 - acc: 0.7186\n",
      "Epoch 7/10\n",
      "1401/1562 [=========================>....] - ETA: 1s - loss: 0.7517 - acc: 0.7366"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "### Data Augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit(x_tr)\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_train, y_train_vec, batch_size=32), \n",
    "                              steps_per_epoch=len(x_train) / 32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
